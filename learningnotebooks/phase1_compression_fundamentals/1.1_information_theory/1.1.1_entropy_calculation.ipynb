{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1.1.1: Entropy Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entropy(probabilities):\n",
    "    probabilities = np.array(probabilities)\n",
    "    probabilities = probabilities[probabilities > 0]\n",
    "    return -np.sum(probabilities * np.log2(probabilities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4689955935892812\n",
      "2.584962500721156\n"
     ]
    }
   ],
   "source": [
    "print(entropy([0.9, 0.1]))\n",
    "print(entropy([1/6, 1/6, 1/6, 1/6, 1/6, 1/6]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fair dice has the greatest entropy as there is the most uncertainty in the results. The biased coin has the least entropy as this situation is less uncertain, as it is significantly more likely to recieve a head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
