{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1: Foundations & Data Pipeline\n",
    "\n",
    "**Goals:**\n",
    "- Deep understanding of autoencoder theory\n",
    "- SAR physics and speckle statistics\n",
    "- Audit and verify preprocessing pipeline\n",
    "\n",
    "**Time:** 6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.join(os.getcwd(), '../../src'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage, stats\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your modules\n",
    "try:\n",
    "    from data.preprocessing import *\n",
    "    print(\"Loaded data.preprocessing\")\n",
    "except ImportError as e:\n",
    "    print(f\"Could not load: {e}\")\n",
    "\n",
    "try:\n",
    "    from data.dataset import *\n",
    "    print(\"Loaded data.dataset\")\n",
    "except ImportError as e:\n",
    "    print(f\"Could not load: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Theory Questions (1.5 hours)\n",
    "\n",
    "**Answer in the markdown cells before proceeding.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1: Information Bottleneck\n",
    "\n",
    "Your autoencoder compresses 256x256x1 (65,536 dims) to 16x16x64 (16,384 dims).\n",
    "\n",
    "a) Why does this force learning useful features?\n",
    "\n",
    "b) For 3 bits/pixel entropy, calculate total input entropy. Is bottleneck tight enough?\n",
    "\n",
    "c) How to detect if bottleneck is too tight or too loose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "a) \n",
    "\n",
    "b) \n",
    "\n",
    "c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2: SAR Physics\n",
    "\n",
    "Predict brightness and explain physics for:\n",
    "- a) Calm lake at 35 deg incidence\n",
    "- b) Lake with 30cm waves\n",
    "- c) Dry plowed field\n",
    "- d) Same field after rain\n",
    "- e) Dense forest\n",
    "- f) Metal bridge (double-bounce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "a) \n",
    "\n",
    "b) \n",
    "\n",
    "c) \n",
    "\n",
    "d) \n",
    "\n",
    "e) \n",
    "\n",
    "f) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3: Speckle\n",
    "\n",
    "Sentinel-1 GRD has ~4.4 looks.\n",
    "\n",
    "a) What does \"4.4 looks\" mean? Resolution trade-off?\n",
    "\n",
    "b) Expected CV? Show formula.\n",
    "\n",
    "c) Reconstruction has CV=0.35 instead of 0.48. Desirable? Cause?\n",
    "\n",
    "d) How distinguish speckle reduction from texture smoothing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "a) \n",
    "\n",
    "b) \n",
    "\n",
    "c) \n",
    "\n",
    "d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.4: Preprocessing\n",
    "\n",
    "Pipeline: log transform -> clip [-25, +5] dB -> normalize [0,1]\n",
    "\n",
    "a) Why log transform?\n",
    "\n",
    "b) What gets clipped at each bound?\n",
    "\n",
    "c) Why not normalize each image independently?\n",
    "\n",
    "d) What params for test inference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "a) \n",
    "\n",
    "b) \n",
    "\n",
    "c) \n",
    "\n",
    "d) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.5: Loss Functions\n",
    "\n",
    "a) Why does MSE alone produce blur?\n",
    "\n",
    "b) What does SSIM measure that MSE ignores?\n",
    "\n",
    "c) For speckly SAR, is exact pixel preservation important?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "a) \n",
    "\n",
    "b) \n",
    "\n",
    "c) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: Preprocessing Audit (2 hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1: Invalid Value Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_array = np.array([\n",
    "    [0.1, 0.0, -0.1],\n",
    "    [np.nan, np.inf, 0.5],\n",
    "    [1e-10, 1e10, 0.3]\n",
    "], dtype=np.float32)\n",
    "\n",
    "print(\"Test array with problematic values:\")\n",
    "print(test_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test your function\n",
    "# result = handle_invalid_values(test_array)\n",
    "# assert np.all(np.isfinite(result))\n",
    "# assert np.all(result >= 0)\n",
    "# print(\"PASSED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2: dB Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    (1.0, 0.0),\n",
    "    (10.0, 10.0),\n",
    "    (0.1, -10.0),\n",
    "    (0.01, -20.0),\n",
    "]\n",
    "\n",
    "for intensity, expected in test_cases:\n",
    "    actual = 10 * np.log10(intensity)\n",
    "    print(f\"{intensity} -> {actual:.1f} dB (expected: {expected})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test your to_db function against these values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.3: Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = -25, 5\n",
    "test_db = np.array([[-30, -25, -20], [-10, 0, 5], [5, 10, 15]])\n",
    "expected = np.array([[0.0, 0.0, 0.167], [0.5, 0.833, 1.0], [1.0, 1.0, 1.0]])\n",
    "\n",
    "print(f\"Input (dB):\\n{test_db}\")\n",
    "print(f\"\\nExpected output:\\n{expected}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test your normalize function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.4: Roundtrip Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "original = np.random.gamma(shape=4.4, scale=0.1, size=(64, 64)).astype(np.float32)\n",
    "print(f\"Original: range=[{original.min():.4f}, {original.max():.4f}], mean={original.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test roundtrip\n",
    "# preprocessed, params = preprocess_complete(original)\n",
    "# reconstructed = inverse_preprocess(preprocessed, params)\n",
    "# error = np.abs(original - reconstructed).mean()\n",
    "# print(f\"Mean absolute error: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Speckle Analysis (1.5 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_local_cv(image, window_size=32):\n",
    "    from scipy.ndimage import uniform_filter\n",
    "    image_safe = np.maximum(image, 1e-10)\n",
    "    local_mean = uniform_filter(image_safe, size=window_size)\n",
    "    local_sq_mean = uniform_filter(image_safe**2, size=window_size)\n",
    "    local_var = np.maximum(local_sq_mean - local_mean**2, 0)\n",
    "    local_std = np.sqrt(local_var)\n",
    "    return local_std / (local_mean + 1e-10)\n",
    "\n",
    "def estimate_enl(image):\n",
    "    image_clean = image[image > 0]\n",
    "    cv = np.std(image_clean) / np.mean(image_clean)\n",
    "    return 1 / (cv ** 2), cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on synthetic data\n",
    "cv_map = compute_local_cv(original, window_size=16)\n",
    "enl, cv = estimate_enl(original)\n",
    "\n",
    "print(f\"Measured CV: {cv:.3f}\")\n",
    "print(f\"Expected CV (L=4.4): {1/np.sqrt(4.4):.3f}\")\n",
    "print(f\"Estimated ENL: {enl:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "axes[0].imshow(original, cmap='gray')\n",
    "axes[0].set_title('Original')\n",
    "im = axes[1].imshow(cv_map, cmap='viridis', vmin=0, vmax=1)\n",
    "axes[1].set_title(f'Local CV (mean={cv_map.mean():.3f})')\n",
    "plt.colorbar(im, ax=axes[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Speckle Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize and fit gamma\n",
    "image_clean = original[original > 0]\n",
    "normalized = image_clean / np.mean(image_clean)\n",
    "shape, loc, scale = stats.gamma.fit(normalized, floc=0)\n",
    "\n",
    "print(f\"Fitted shape (ENL): {shape:.2f}\")\n",
    "print(f\"Expected ENL: 4.4\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.hist(normalized, bins=100, density=True, alpha=0.7, label='Data')\n",
    "x = np.linspace(0, 4, 200)\n",
    "ax.plot(x, stats.gamma.pdf(x, a=4.4, scale=1/4.4), 'r-', lw=2, label='Gamma(L=4.4)')\n",
    "ax.plot(x, stats.gamma.pdf(x, a=shape, scale=scale), 'g--', lw=2, label=f'Fitted(L={shape:.1f})')\n",
    "ax.legend()\n",
    "ax.set_xlabel('Normalized Intensity')\n",
    "ax.set_ylabel('Density')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Day 1 Checklist\n",
    "\n",
    "- [ ] Answered all theory questions\n",
    "- [ ] Invalid value handling test passed\n",
    "- [ ] dB conversion test passed  \n",
    "- [ ] Normalization test passed\n",
    "- [ ] Roundtrip test passed\n",
    "- [ ] Speckle statistics analyzed\n",
    "- [ ] Documented issues/fixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "*Document issues and fixes here:*\n",
    "\n",
    "1. \n",
    "2. \n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
