{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 1: Foundations & Data Pipeline\n",
    "\n",
    "**Goals:**\n",
    "- Deep understanding of autoencoder theory\n",
    "- SAR physics and speckle statistics\n",
    "- Audit and verify your preprocessing pipeline\n",
    "\n",
    "**Time:** 6 hours\n",
    "\n",
    "**Approach:** This notebook guides you through exercises with instructions. Write all code yourself. If stuck, refer to the reference notebooks or your existing `src/` modules.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import the libraries you'll need:\n",
    "- `numpy` for numerical operations\n",
    "- `matplotlib.pyplot` for plotting\n",
    "- `scipy.stats` for statistical distributions\n",
    "- `scipy.ndimage` for image filtering\n",
    "\n",
    "Also add your `src/` directory to the Python path so you can import your modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as mpl\n",
    "import scipy.stats as stats\n",
    "import scipy.ndimage as ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try importing your preprocessing and dataset modules. Print a success message for each, or catch the ImportError and print what went wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your data modules here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Theory Questions (1.5 hours)\n",
    "\n",
    "Answer these questions **in writing** before moving to the coding exercises. Writing forces you to articulate your understanding clearly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1: Information Bottleneck\n",
    "\n",
    "Your autoencoder compresses 256×256×1 images (65,536 values) to a 16×16×64 latent space (16,384 values).\n",
    "\n",
    "**a)** Why does this dimensional reduction force the network to learn useful features rather than simply memorizing inputs?\n",
    "\n",
    "**b)** Natural images typically have 2-4 bits of entropy per pixel when spatial correlations are accounted for. If we assume 3 bits/pixel, what is the total information content of a 256×256 input? Compare this to the capacity of your latent space (assuming 32-bit floats). Is your bottleneck actually forcing compression?\n",
    "\n",
    "**c)** How would you determine experimentally whether your bottleneck is too tight (losing important information) versus too loose (not learning efficient representations)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "**a)**\n",
    "\n",
    "\n",
    "**b)**\n",
    "\n",
    "\n",
    "**c)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2: SAR Physics\n",
    "\n",
    "For Sentinel-1 C-band SAR, predict the relative brightness (dark / medium / bright / very bright) and explain the physical scattering mechanism for each scenario:\n",
    "\n",
    "**a)** Calm lake water at 35° incidence angle\n",
    "\n",
    "**b)** The same lake with 30cm wind-driven waves\n",
    "\n",
    "**c)** A freshly plowed, dry agricultural field\n",
    "\n",
    "**d)** The same field after heavy rain\n",
    "\n",
    "**e)** Dense coniferous forest\n",
    "\n",
    "**f)** A metal bridge crossing a river (think about what happens when radar hits a corner reflector geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "**a)**\n",
    "\n",
    "**b)**\n",
    "\n",
    "**c)**\n",
    "\n",
    "**d)**\n",
    "\n",
    "**e)**\n",
    "\n",
    "**f)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3: Speckle Statistics\n",
    "\n",
    "Sentinel-1 GRD products have approximately 4.4 equivalent number of looks (ENL).\n",
    "\n",
    "**a)** What does \"4.4 looks\" mean physically? How is ENL related to the trade-off between spatial resolution and radiometric resolution?\n",
    "\n",
    "**b)** For a homogeneous region with L looks, the coefficient of variation (CV = std/mean) of intensity follows a specific formula. What is CV for L=4.4? Show your calculation.\n",
    "\n",
    "**c)** Suppose your autoencoder's reconstruction has CV=0.35 in homogeneous regions, but the input had CV=0.48. What does this mean? Is it desirable? When might it be problematic?\n",
    "\n",
    "**d)** How could you distinguish between beneficial speckle reduction and harmful texture/detail smoothing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "**a)**\n",
    "\n",
    "**b)**\n",
    "\n",
    "**c)**\n",
    "\n",
    "**d)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.4: Preprocessing Rationale\n",
    "\n",
    "A typical SAR preprocessing pipeline consists of:\n",
    "1. Log transform: dB = 10 × log₁₀(intensity)\n",
    "2. Clip to range [-25, +5] dB\n",
    "3. Normalize to [0, 1]\n",
    "\n",
    "**a)** Why apply a log transform before feeding SAR data to a neural network? Think about the dynamic range and distribution of SAR backscatter values.\n",
    "\n",
    "**b)** What physical features or surfaces would be clipped at -25 dB? What about at +5 dB?\n",
    "\n",
    "**c)** A colleague suggests normalizing each image independently to [0, 1] based on its own min/max. Why is this problematic for training a neural network?\n",
    "\n",
    "**d)** When running inference on new data, what normalization parameters should you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "**a)**\n",
    "\n",
    "**b)**\n",
    "\n",
    "**c)**\n",
    "\n",
    "**d)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.5: Loss Function Choice\n",
    "\n",
    "**a)** Why does MSE loss alone tend to produce blurry reconstructions? Hint: think about what the optimal prediction is when there's uncertainty about the exact pixel value.\n",
    "\n",
    "**b)** SSIM measures structural similarity. What specific image properties does it capture that MSE ignores?\n",
    "\n",
    "**c)** For SAR images with inherent speckle noise, is preserving exact pixel values actually important? How should this influence your choice of loss function?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "**a)**\n",
    "\n",
    "**b)**\n",
    "\n",
    "**c)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Preprocessing Audit (2 hours)\n",
    "\n",
    "Now you'll test your preprocessing implementation to make sure it handles edge cases correctly.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1: Test Invalid Value Handling\n",
    "\n",
    "SAR data can contain problematic values that will break a naive log transform:\n",
    "- Zeros (log(0) = -∞)\n",
    "- Negative values (shouldn't exist but sometimes do due to processing artifacts)\n",
    "- NaN and Inf values\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Create a small test array (e.g., 3×3) containing: a normal positive value, zero, a negative value, NaN, Inf, a very small positive value (1e-10), and a very large value (1e10).\n",
    "\n",
    "2. Run this array through your preprocessing function(s).\n",
    "\n",
    "3. Verify that the output:\n",
    "   - Contains no NaN or Inf values (use `np.isfinite()`)\n",
    "   - Contains no negative values\n",
    "   - Is in the expected range [0, 1]\n",
    "\n",
    "4. If any test fails, identify what went wrong and fix your preprocessing code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your test array with problematic values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run through your preprocessing and check results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2: Verify dB Conversion\n",
    "\n",
    "The dB transform is: dB = 10 × log₁₀(intensity)\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Create a list of test cases with known input/output pairs:\n",
    "   - intensity=1.0 → 0 dB\n",
    "   - intensity=10.0 → 10 dB\n",
    "   - intensity=0.1 → -10 dB\n",
    "   - intensity=0.01 → -20 dB\n",
    "\n",
    "2. Test your `to_db()` function (or equivalent) against these known values.\n",
    "\n",
    "3. Assert that your function produces the correct results within a small tolerance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test cases and verify your dB conversion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.3: Verify Normalization\n",
    "\n",
    "Your normalization should:\n",
    "1. Clip values to [vmin, vmax] (e.g., [-25, +5] dB)\n",
    "2. Scale to [0, 1]: normalized = (clipped - vmin) / (vmax - vmin)\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Create a test array in dB with values that span below vmin, within range, and above vmax. For example:\n",
    "   ```\n",
    "   [[-30, -25, -20],\n",
    "    [-10,   0,   5],\n",
    "    [  5,  10,  15]]\n",
    "   ```\n",
    "\n",
    "2. Calculate by hand what the expected normalized output should be.\n",
    "\n",
    "3. Run your normalization function and compare to your expected values.\n",
    "\n",
    "4. Verify that all outputs are in [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your normalization function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.4: Roundtrip Test\n",
    "\n",
    "A critical test: if you preprocess data and then invert the preprocessing, you should recover the original values (for values that weren't clipped).\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Generate synthetic SAR-like data using a gamma distribution:\n",
    "   ```python\n",
    "   original = np.random.gamma(shape=4.4, scale=0.1, size=(64, 64))\n",
    "   ```\n",
    "   This simulates intensity data with ~4.4 looks.\n",
    "\n",
    "2. Run the data through your complete preprocessing pipeline. Make sure to save any parameters needed for inversion (vmin, vmax, etc.).\n",
    "\n",
    "3. Invert the preprocessing to get back to linear intensity.\n",
    "\n",
    "4. For pixels that weren't clipped, calculate the relative error between original and reconstructed values. It should be very small (<0.1%).\n",
    "\n",
    "**Hint:** To find non-clipped pixels, convert original to dB and check which values fall within [vmin, vmax]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roundtrip test: preprocess -> inverse -> compare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Speckle Analysis (1.5 hours)\n",
    "\n",
    "Now you'll implement and test functions to analyze speckle statistics.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.5: Implement Local CV Computation\n",
    "\n",
    "The coefficient of variation (CV = std/mean) measured locally tells you about speckle characteristics.\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Write a function `compute_local_cv(image, window_size)` that:\n",
    "\n",
    "1. Computes local mean using `scipy.ndimage.uniform_filter`\n",
    "2. Computes local variance using the identity: Var(X) = E[X²] - E[X]²\n",
    "   - Local variance = uniform_filter(image²) - (uniform_filter(image))²\n",
    "3. Computes CV = local_std / local_mean\n",
    "4. Handles edge cases (avoid division by zero)\n",
    "\n",
    "Test it on your synthetic gamma data and visualize the CV map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement compute_local_cv function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on synthetic data and visualize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.6: Implement ENL Estimation\n",
    "\n",
    "The Equivalent Number of Looks can be estimated from intensity data as:\n",
    "\n",
    "ENL = (mean / std)² = 1 / CV²\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Write a function `estimate_enl(image)` that:\n",
    "1. Filters out zero or negative values\n",
    "2. Computes the global mean and standard deviation\n",
    "3. Returns the ENL estimate\n",
    "\n",
    "Test it on your synthetic gamma(4.4, 0.1) data. The estimated ENL should be close to 4.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement estimate_enl function and test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.7: Verify Speckle Distribution\n",
    "\n",
    "For fully developed speckle with L looks, normalized intensity (I/mean) follows a Gamma(L, 1/L) distribution.\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Normalize your synthetic data by dividing by its mean.\n",
    "\n",
    "2. Fit a gamma distribution to the normalized data using `scipy.stats.gamma.fit()`. Use `floc=0` to fix the location parameter at zero.\n",
    "\n",
    "3. Create a plot showing:\n",
    "   - Histogram of your normalized data\n",
    "   - Theoretical gamma PDF for L=4.4\n",
    "   - Fitted gamma PDF\n",
    "\n",
    "4. Compare the fitted shape parameter to the expected value of 4.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit gamma distribution and create comparison plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Analyze Your Actual Dataset (if available)\n",
    "\n",
    "If you have preprocessed patches saved, analyze their statistics.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.8: Dataset Statistics\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Load your preprocessed training patches (update the path as needed).\n",
    "\n",
    "2. Compute and print basic statistics: shape, min, max, mean, std.\n",
    "\n",
    "3. Check for problems:\n",
    "   - Any values < 0?\n",
    "   - Any values > 1?\n",
    "   - Any NaN or Inf?\n",
    "\n",
    "4. Plot a histogram of all pixel values.\n",
    "\n",
    "5. If you find any issues, trace them back to your preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and analyze your patches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 1 Checklist\n",
    "\n",
    "Before moving to Day 2, verify:\n",
    "\n",
    "- [ ] Answered all theory questions (Q1.1 - Q1.5) thoughtfully\n",
    "- [ ] Invalid value handling works correctly\n",
    "- [ ] dB conversion matches expected values\n",
    "- [ ] Normalization produces [0, 1] output with correct clipping\n",
    "- [ ] Roundtrip preprocessing test passes\n",
    "- [ ] Local CV computation implemented and tested\n",
    "- [ ] ENL estimation gives reasonable results (~4.4 for synthetic data)\n",
    "- [ ] Speckle distribution matches gamma distribution\n",
    "- [ ] Dataset statistics look reasonable (if applicable)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes and Issues Found\n",
    "\n",
    "*Document any bugs you found and fixed, or insights you gained:*\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
