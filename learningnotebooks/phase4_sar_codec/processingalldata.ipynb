{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc3bb192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\CNNAutoencoderProject\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "from scipy.ndimage import uniform_filter\n",
    "from scipy.stats import gamma as gamma_dist\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from glob import glob\n",
    "import sys\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "project_root = Path.cwd().parents[1] # Up from learningnotebooks/phase4_sar_codec/\n",
    "print(project_root)\n",
    "sys.path.insert(0, str(project_root / \"src\"))\n",
    "\n",
    "from utils.io import load_sar_image, find_all_sar_files, get_info\n",
    "from data.preprocessing import preprocess_sar_complete, extract_patches\n",
    "\n",
    "\n",
    "rawdir = project_root/\"data\"/\"raw\"\n",
    "outputdir = project_root/\"data\"/\"patches\"\n",
    "checkpointdir = project_root/\"checkpoints\"\n",
    "patchsize = 256\n",
    "stride = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "284d49df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sar_files = find_all_sar_files(rawdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84050e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total .SAFE folders: 22\n",
      "\n"
     ]
    }
   ],
   "source": [
    "safe_folders = list(rawdir.glob(\"*.SAFE\"))\n",
    "print(f\"Total .SAFE folders: {len(safe_folders)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4c1707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete: 22\n",
      "Incomplete: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "complete = []\n",
    "incomplete = []\n",
    "\n",
    "for folder in safe_folders:\n",
    "    measurement_dir = folder / \"measurement\"\n",
    "    if measurement_dir.exists():\n",
    "        tiffs = list(measurement_dir.glob(\"*.tiff\"))\n",
    "        if len(tiffs) >= 2:\n",
    "            complete.append(folder.name)\n",
    "        else:\n",
    "            incomplete.append((folder.name, len(tiffs)))\n",
    "    else:\n",
    "        incomplete.append((folder.name, \"no measurement folder\"))\n",
    "\n",
    "print(f\"Complete: {len(complete)}\")\n",
    "print(f\"Incomplete: {len(incomplete)}\\n\")\n",
    "\n",
    "if incomplete:\n",
    "    print(\"Incomplete folders:\")\n",
    "    for name, issue in incomplete:\n",
    "        print(f\"  {name}: {issue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84d4dbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder exists: True\n",
      "\n",
      "Contents:\n",
      "  annotation\n",
      "  manifest.safe\n",
      "  measurement\n",
      "  preview\n",
      "  S1A_IW_GRDH_1SDV_20260117T061452_20260117T061517_062803_07E08D_824A.SAFE-report-20260117T070206.pdf\n",
      "  support\n",
      "\n",
      "Measurement folder check:\n",
      "  'measurement' exists: True\n",
      "  'MEASUREMENT' exists: True\n"
     ]
    }
   ],
   "source": [
    "folder = rawdir / \"S1A_IW_GRDH_1SDV_20260117T061452_20260117T061517_062803_07E08D_824A.SAFE\"\n",
    "\n",
    "print(f\"Folder exists: {folder.exists()}\")\n",
    "print(f\"\\nContents:\")\n",
    "for item in folder.iterdir():\n",
    "    print(f\"  {item.name}\")\n",
    "    \n",
    "# Check if measurement exists with different casing\n",
    "print(f\"\\nMeasurement folder check:\")\n",
    "print(f\"  'measurement' exists: {(folder / 'measurement').exists()}\")\n",
    "print(f\"  'MEASUREMENT' exists: {(folder / 'MEASUREMENT').exists()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcbd16b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46 TIFF files:\n",
      "\n",
      "  S1A | 20251114 | s1a-iw-grd-vh-20251114t225109-20251114t225134-0618...\n",
      "  S1A | 20251114 | s1a-iw-grd-vv-20251114t225109-20251114t225134-0618...\n",
      "  S1A | 20260111 | s1a-iw-grd-vh-20260111t095455-20260111t095520-0627...\n",
      "  S1A | 20260111 | s1a-iw-grd-vv-20260111t095455-20260111t095520-0627...\n",
      "  S1A | 20260111 | s1a-iw-grd-vh-20260111t233937-20260111t234002-0627...\n",
      "  S1A | 20260111 | s1a-iw-grd-vv-20260111t233937-20260111t234002-0627...\n",
      "  S1A | 20260116 | s1a-iw-grd-vh-20260116t113541-20260116t113606-0627...\n",
      "  S1A | 20260116 | s1a-iw-grd-vv-20260116t113541-20260116t113606-0627...\n",
      "  S1A | 20260116 | s1a-iw-grd-vh-20260116t231538-20260116t231603-0627...\n",
      "  S1A | 20260116 | s1a-iw-grd-vv-20260116t231538-20260116t231603-0627...\n",
      "  S1A | 20260117 | s1a-iw-grd-vh-20260117t061452-20260117t061517-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vv-20260117t061452-20260117t061517-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vh-20260117t104141-20260117t104206-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vv-20260117t104141-20260117t104206-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vh-20260117t104256-20260117t104321-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vv-20260117t104256-20260117t104321-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vh-20260117t122220-20260117t122245-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vv-20260117t122220-20260117t122245-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vh-20260117t125115-20260117t125140-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vv-20260117t125115-20260117t125140-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vh-20260117t154520-20260117t154545-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vv-20260117t154520-20260117t154545-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vh-20260117t172513-20260117t172538-0628...\n",
      "  S1A | 20260117 | s1a-iw-grd-vv-20260117t172513-20260117t172538-0628...\n",
      "  S1C | 20251215 | s1c-iw-grd-vh-20251215t084123-20251215t084148-0054...\n",
      "  S1C | 20251215 | s1c-iw-grd-vv-20251215t084123-20251215t084148-0054...\n",
      "  S1C | 20260116 | s1c-iw-grd-vh-20260116t173029-20260116t173054-0059...\n",
      "  S1C | 20260116 | s1c-iw-grd-vv-20260116t173029-20260116t173054-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vh-20260117t052429-20260117t052454-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vv-20260117t052429-20260117t052454-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vh-20260117t052609-20260117t052634-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vv-20260117t052609-20260117t052634-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vh-20260117t052634-20260117t052659-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vv-20260117t052634-20260117t052659-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vh-20260117t090611-20260117t090636-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vv-20260117t090611-20260117t090636-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vh-20260117t180911-20260117t180936-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vv-20260117t180911-20260117t180936-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vh-20260117t203427-20260117t203452-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vv-20260117t203427-20260117t203452-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vh-20260117t225139-20260117t225204-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vv-20260117t225139-20260117t225204-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vh-20260117t225204-20260117t225229-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vv-20260117t225204-20260117t225229-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vh-20260117t052634-20260117t052659-0059...\n",
      "  S1C | 20260117 | s1c-iw-grd-vv-20260117t052634-20260117t052659-0059...\n"
     ]
    }
   ],
   "source": [
    "print(f\"Found {len(sar_files)} TIFF files:\\n\")\n",
    "for f in sar_files:\n",
    "    info = get_info(f)\n",
    "    print(f\"  {info['satellite'].upper()} | {info.get('date', '?')} | {Path(f).name[:50]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1801e8dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (16704, 25424)\n",
      "Dtype: uint16\n",
      "Array size: 1.70 GB\n"
     ]
    }
   ],
   "source": [
    "path = sar_files[0]\n",
    "import rasterio\n",
    "import time\n",
    "with rasterio.open(path) as src:\n",
    "    print(f\"Shape: {src.shape}\")\n",
    "    print(f\"Dtype: {src.dtypes[0]}\")\n",
    "    image = src.read(1).astype(np.float32)\n",
    "    print(f\"Array size: {image.nbytes / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2352e2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded bounds: [14.77, 24.54] dB\n"
     ]
    }
   ],
   "source": [
    "bounds_file = checkpointdir / \"global_bounds.npy\"\n",
    "\n",
    "if bounds_file.exists():\n",
    "    bounds = np.load(bounds_file, allow_pickle=True).item()\n",
    "    global_vmin = bounds[\"vmin\"]\n",
    "    global_vmax = bounds[\"vmax\"]\n",
    "    print(f\"Loaded bounds: [{global_vmin:.2f}, {global_vmax:.2f}] dB\")\n",
    "else:\n",
    "    # Run the scanning loop to compute them\n",
    "    print(\"No saved bounds, computing...\")\n",
    "\n",
    "    all_vmins = []\n",
    "    all_vmaxs = []\n",
    "\n",
    "\n",
    "\n",
    "    for path in tqdm(sar_files, desc=\"Scanning\"):\n",
    "        print(f\"\\n{path}\")\n",
    "        \n",
    "        t0 = time.time()\n",
    "        with rasterio.open(path) as src:\n",
    "            image = src.read(1).astype(np.float32)\n",
    "        print(f\"  Read: {time.time() - t0:.1f}s\")\n",
    "        \n",
    "        t0 = time.time()\n",
    "        valid = image[image > 0]\n",
    "        del image\n",
    "        gc.collect()\n",
    "        print(f\"  Valid mask: {time.time() - t0:.1f}s\")\n",
    "        \n",
    "        if len(valid) == 0:\n",
    "            continue\n",
    "        \n",
    "        t0 = time.time()\n",
    "        if len(valid) > 100_000:\n",
    "            idx = np.random.randint(0, len(valid), 100_000)\n",
    "            valid = valid[idx]\n",
    "        print(f\"  Subsample: {time.time() - t0:.1f}s\")\n",
    "        \n",
    "        t0 = time.time()\n",
    "        image_db = 10 * np.log10(np.maximum(valid, 1e-10))\n",
    "        all_vmins.append(np.percentile(image_db, 1))\n",
    "        all_vmaxs.append(np.percentile(image_db, 99))\n",
    "        print(f\"  Percentiles: {time.time() - t0:.1f}s\")\n",
    "        \n",
    "        del valid, image_db\n",
    "        gc.collect()\n",
    "\n",
    "    global_vmin = np.median(all_vmins)\n",
    "    global_vmax = np.median(all_vmaxs)\n",
    "\n",
    "\n",
    "    print(f\"\\nGlobal bounds: [{global_vmin:.2f}, {global_vmax:.2f}] dB\")\n",
    "    np.save(checkpointdir / \"global_bounds.npy\", {\n",
    "        \"vmin\" : global_vmin,\n",
    "        \"vmax\" : global_vmax,\n",
    "        \"all_vmins\" : all_vmins,\n",
    "        \"all_vmaxs\" : all_vmaxs\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1ce603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass 2 Extracting Patches...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b325c6be13964ab1ba84757fb5c8e2d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  s1a-iw-grd-vh-20251114t225109-20251114t2... : 12705 patches | Mem: 0.0 GB\n",
      "  s1a-iw-grd-vv-20251114t225109-20251114t2... : 13782 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vh-20260111t095455-20260111t0... : 9555 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vv-20260111t095455-20260111t0... : 16124 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vh-20260111t233937-20260111t2... : 24973 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vv-20260111t233937-20260111t2... : 2573 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vh-20260116t113541-20260116t1... : 17027 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vv-20260116t113541-20260116t1... : 9247 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vh-20260116t231538-20260116t2... : 25054 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vv-20260116t231538-20260116t2... : 16855 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vh-20260117t061452-20260117t0... : 24027 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vv-20260117t061452-20260117t0... : 9641 patches | Mem: 1.1 GB\n",
      "  s1a-iw-grd-vh-20260117t104141-20260117t1... : 12769 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vv-20260117t104141-20260117t1... : 8240 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vh-20260117t104256-20260117t1... : 25117 patches | Mem: 1.1 GB\n",
      "  s1a-iw-grd-vv-20260117t104256-20260117t1... : 5975 patches | Mem: 1.1 GB\n",
      "  s1a-iw-grd-vh-20260117t122220-20260117t1... : 19989 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vv-20260117t122220-20260117t1... : 8705 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vh-20260117t125115-20260117t1... : 9304 patches | Mem: 1.1 GB\n",
      "  s1a-iw-grd-vv-20260117t125115-20260117t1... : 25112 patches | Mem: 1.1 GB\n",
      "  s1a-iw-grd-vh-20260117t154520-20260117t1... : 18174 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vv-20260117t154520-20260117t1... : 24012 patches | Mem: 0.6 GB\n",
      "  s1a-iw-grd-vh-20260117t172513-20260117t1... : 20542 patches | Mem: 1.2 GB\n",
      "  s1a-iw-grd-vv-20260117t172513-20260117t1... : 14507 patches | Mem: 1.2 GB\n",
      "  s1c-iw-grd-vh-20251215t084123-20251215t0... : 24297 patches | Mem: 0.6 GB\n",
      "  s1c-iw-grd-vv-20251215t084123-20251215t0... : 9962 patches | Mem: 1.3 GB\n",
      "  s1c-iw-grd-vh-20260116t173029-20260116t1... : 21003 patches | Mem: 1.3 GB\n",
      "  s1c-iw-grd-vv-20260116t173029-20260116t1... : 11004 patches | Mem: 1.3 GB\n",
      "  s1c-iw-grd-vh-20260117t052429-20260117t0... : 18841 patches | Mem: 0.6 GB\n",
      "  s1c-iw-grd-vv-20260117t052429-20260117t0... : 23132 patches | Mem: 1.3 GB\n",
      "  s1c-iw-grd-vh-20260117t052609-20260117t0... : 17870 patches | Mem: 1.3 GB\n",
      "  s1c-iw-grd-vv-20260117t052609-20260117t0... : 11063 patches | Mem: 0.6 GB\n",
      "  s1c-iw-grd-vh-20260117t052634-20260117t0... : 24443 patches | Mem: 0.6 GB\n",
      "  s1c-iw-grd-vv-20260117t052634-20260117t0... : 10203 patches | Mem: 1.3 GB\n",
      "  s1c-iw-grd-vh-20260117t090611-20260117t0... : 14328 patches | Mem: 0.6 GB\n",
      "  s1c-iw-grd-vv-20260117t090611-20260117t0... : 23563 patches | Mem: 0.6 GB\n",
      "  s1c-iw-grd-vh-20260117t180911-20260117t1... : 6520 patches | Mem: 1.3 GB\n",
      "  s1c-iw-grd-vv-20260117t180911-20260117t1... : 22064 patches | Mem: 0.6 GB\n",
      "  s1c-iw-grd-vh-20260117t203427-20260117t2... : 10038 patches | Mem: 0.6 GB\n",
      "  s1c-iw-grd-vv-20260117t203427-20260117t2... : 24977 patches | Mem: 1.4 GB\n",
      "  s1c-iw-grd-vh-20260117t225139-20260117t2... : 23707 patches | Mem: 1.4 GB\n",
      "  s1c-iw-grd-vv-20260117t225139-20260117t2... : 15817 patches | Mem: 0.6 GB\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "1617166336 requested and 0 written",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 44\u001b[39m\n\u001b[32m     38\u001b[39m filestats.append({\n\u001b[32m     39\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m: filename,\n\u001b[32m     40\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m'\u001b[39m: image_shape,\n\u001b[32m     41\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mpatches\u001b[39m\u001b[33m'\u001b[39m: n_patches\n\u001b[32m     42\u001b[39m })\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m n_patches > \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputdir\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_patches.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m patches, positions\n\u001b[32m     47\u001b[39m gc.collect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\CNNAutoencoderProject\\venv\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:572\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(file, arr, allow_pickle)\u001b[39m\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m file_ctx \u001b[38;5;28;01mas\u001b[39;00m fid:\n\u001b[32m    571\u001b[39m     arr = np.asanyarray(arr)\n\u001b[32m--> \u001b[39m\u001b[32m572\u001b[39m     \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwrite_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\CNNAutoencoderProject\\venv\\Lib\\site-packages\\numpy\\lib\\_format_impl.py:772\u001b[39m, in \u001b[36mwrite_array\u001b[39m\u001b[34m(fp, array, version, allow_pickle, pickle_kwargs)\u001b[39m\n\u001b[32m    770\u001b[39m             fp.write(chunk.tobytes(\u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    771\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m isfileobj(fp):\n\u001b[32m--> \u001b[39m\u001b[32m772\u001b[39m     \u001b[43marray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtofile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    773\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    774\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m numpy.nditer(\n\u001b[32m    775\u001b[39m             array, flags=[\u001b[33m'\u001b[39m\u001b[33mexternal_loop\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mbuffered\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mzerosize_ok\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m    776\u001b[39m             buffersize=buffersize, order=\u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m):\n",
      "\u001b[31mOSError\u001b[39m: 1617166336 requested and 0 written"
     ]
    }
   ],
   "source": [
    "\n",
    "min_valid = 0.9\n",
    "\n",
    "all_patches = []\n",
    "filestats = []\n",
    "\n",
    "print(\"Pass 2 Extracting Patches...\\n\")\n",
    "\n",
    "for path in tqdm(sar_files, desc = \"Processing\"):\n",
    "    filename = Path(path).stem\n",
    "\n",
    "    mem_gb = psutil.Process().memory_info().rss / 1e9\n",
    "    if mem_gb > 25:  # bail out before crash\n",
    "        print(f\"WARNING: Memory at {mem_gb:.1f} GB, stopping early\")\n",
    "        break\n",
    "\n",
    "    image = load_sar_image(path)\n",
    "    image_shape=image.shape\n",
    "\n",
    "    normalised, params = preprocess_sar_complete(\n",
    "        image, \n",
    "        vmin=global_vmin, \n",
    "        vmax=global_vmax\n",
    "    )\n",
    "    del image\n",
    "    gc.collect()\n",
    "    \n",
    "    # Extract patches\n",
    "    patches, positions = extract_patches(\n",
    "        normalised,\n",
    "        patch_size=patchsize,\n",
    "        stride=stride,\n",
    "        min_valid=min_valid\n",
    "    )\n",
    "    del normalised\n",
    "    gc.collect()\n",
    "    \n",
    "    n_patches = len(patches)\n",
    "    filestats.append({\n",
    "        'filename': filename,\n",
    "        'shape': image_shape,\n",
    "        'patches': n_patches\n",
    "    })\n",
    "    if n_patches > 0:\n",
    "        np.save(outputdir / f\"{filename}_patches.npy\", patches)\n",
    "\n",
    "    del patches, positions\n",
    "    gc.collect()\n",
    "    \n",
    "    \n",
    "    tqdm.write(f\"  {filename[:40]}... : {n_patches} patches | Mem: {mem_gb:.1f} GB\")\n",
    "    \n",
    "\n",
    "print(f\"\\nProcessed {len(sar_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3af47f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files saved: 0\n",
      "Free space: 78.1 GB\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"patches\")\n",
    "\n",
    "# Check what's done\n",
    "existing = list(output_dir.glob(\"*.npy\"))\n",
    "print(f\"Files saved: {len(existing)}\")\n",
    "\n",
    "# Check disk space\n",
    "import shutil\n",
    "total, used, free = shutil.disk_usage(\"D:/\")\n",
    "print(f\"Free space: {free / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d34d2478-da26-4cdc-b7ed-c58e95f3803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already saved: 46 files\n",
      "Remaining: 1 files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49824c4b6bce4d1e850d03bcaea048ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  s1c-iw-grd-vv-20260117t225204-20260117t2... : 9436 patches | Mem: 7.9 GB\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "existing = set(f.stem.replace(\"_patches\", \"\") for f in outputdir.glob(\"*.npy\"))\n",
    "print(f\"Already saved: {len(existing)} files\")\n",
    "\n",
    "# Find remaining files\n",
    "remaining = [p for p in sar_files if Path(p).stem not in existing]\n",
    "print(f\"Remaining: {len(remaining)} files\")\n",
    "\n",
    "# Process only remaining files\n",
    "for path in tqdm(remaining, desc=\"Processing\"):\n",
    "    filename = Path(path).stem\n",
    "    \n",
    "    mem_gb = psutil.Process().memory_info().rss / 1e9\n",
    "    if mem_gb > 25:\n",
    "        print(f\"WARNING: Memory at {mem_gb:.1f} GB, stopping early\")\n",
    "        break\n",
    "    \n",
    "    image = load_sar_image(path)\n",
    "    image_shape = image.shape\n",
    "    \n",
    "    normalised, params = preprocess_sar_complete(\n",
    "        image, vmin=global_vmin, vmax=global_vmax\n",
    "    )\n",
    "    del image\n",
    "    gc.collect()\n",
    "    \n",
    "    patches, positions = extract_patches(\n",
    "        normalised, patch_size=patchsize, stride=stride, min_valid=min_valid\n",
    "    )\n",
    "    del normalised\n",
    "    gc.collect()\n",
    "    \n",
    "    n_patches = len(patches)\n",
    "    filestats.append({\n",
    "        'filename': filename,\n",
    "        'shape': image_shape,\n",
    "        'patches': n_patches\n",
    "    })\n",
    "    \n",
    "    if n_patches > 0:\n",
    "        np.save(outputdir / f\"{filename}_patches.npy\", patches)\n",
    "    \n",
    "    del patches, positions\n",
    "    gc.collect()\n",
    "    \n",
    "    tqdm.write(f\"  {filename[:40]}... : {n_patches} patches | Mem: {mem_gb:.1f} GB\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56847338-b82c-48d5-bb16-6c8f75610c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total TIFFs: 44\n",
      "Saved patches: 47\n",
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "# Get all tiff filenames (stems)\n",
    "tiff_stems = set(Path(p).stem for p in sar_files)\n",
    "\n",
    "# Get all saved patch filenames (remove \"_patches\" suffix)\n",
    "saved_stems = set(f.stem.replace(\"_patches\", \"\") for f in outputdir.glob(\"*.npy\"))\n",
    "\n",
    "# Find missing\n",
    "missing = tiff_stems - saved_stems\n",
    "\n",
    "print(f\"Total TIFFs: {len(tiff_stems)}\")\n",
    "print(f\"Saved patches: {len(saved_stems)}\")\n",
    "print(f\"Missing: {len(missing)}\")\n",
    "\n",
    "if missing:\n",
    "    print(\"\\nMissing files:\")\n",
    "    for m in sorted(missing):\n",
    "        print(f\"  {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "017e3cc2-16fa-4d75-a300-81ee110440f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches: 720,953\n"
     ]
    }
   ],
   "source": [
    "import struct\n",
    "\n",
    "def get_npy_shape(filepath):\n",
    "    \"\"\"Read shape from .npy header without loading data\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        # Skip magic number and version\n",
    "        f.read(8)\n",
    "        # Read header length\n",
    "        header_len = struct.unpack('<H', f.read(2))[0]\n",
    "        # Read header\n",
    "        header = f.read(header_len).decode('latin1')\n",
    "        # Parse shape from header string\n",
    "        shape_start = header.find('(') + 1\n",
    "        shape_end = header.find(')')\n",
    "        shape_str = header[shape_start:shape_end]\n",
    "        shape = tuple(int(x.strip()) for x in shape_str.split(',') if x.strip())\n",
    "        return shape\n",
    "\n",
    "total_patches = 0\n",
    "for f in outputdir.glob(\"*_patches.npy\"):\n",
    "    shape = get_npy_shape(f)\n",
    "    total_patches += shape[0]\n",
    "    \n",
    "print(f\"Total patches: {total_patches:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b98e1639-d549-4ada-b298-925e88a7ff5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size: 182.5 GB\n"
     ]
    }
   ],
   "source": [
    "total_bytes = sum(f.stat().st_size for f in outputdir.glob(\"*_patches.npy\"))\n",
    "print(f\"Total size: {total_bytes / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8c1cf27-f2df-43aa-802d-c7fa982c47a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch shape: (256, 256)\n"
     ]
    }
   ],
   "source": [
    "patch_files = list(outputdir.glob(\"*patches.npy\"))\n",
    "\n",
    "sample = np.load(patch_files[0], mmap_mode=\"r\")\n",
    "patch_shape = sample.shape[1:]\n",
    "print(f\"Patch shape: {patch_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bb62188-d7bd-46e6-b017-7b2f493cb872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata only\n",
    "metadata = {\n",
    "    'vmin': global_vmin,\n",
    "    'vmax': global_vmax,\n",
    "    'patch_size': patchsize,\n",
    "    'stride': stride,\n",
    "    'min_valid': min_valid,\n",
    "    'num_patches': total_patches,\n",
    "}\n",
    "np.save(outputdir / 'metadata.npy', metadata, allow_pickle=True)\n",
    "\n",
    "# Save shuffle index\n",
    "shuffle_idx = np.random.permutation(total_patches)\n",
    "np.save(outputdir / \"shuffle_idx.npy\", shuffle_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e914035-ab64-469e-8376-62d7cd11c91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0827b374cf041828c887be57f0364b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing:   0%|          | 0/44 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches: 720,953\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Delete the old combined file\n",
    "(outputdir / \"all_patches.npy\").unlink()\n",
    "\n",
    "# Re-run indexing (exclude all_patches.npy)\n",
    "patch_files = sorted(f for f in outputdir.glob(\"*_patches.npy\") if f.name != \"all_patches.npy\")\n",
    "\n",
    "file_index = []\n",
    "for f in tqdm(patch_files, desc=\"Indexing\"):\n",
    "    shape = get_npy_shape(f)\n",
    "    file_index.append((f, shape[0]))\n",
    "\n",
    "total_patches = sum(n for _, n in file_index)\n",
    "print(f\"Total patches: {total_patches:,}\")\n",
    "\n",
    "np.random.seed(42)\n",
    "shuffle_idx = np.random.permutation(total_patches)\n",
    "np.save(outputdir / \"shuffle_idx.npy\", shuffle_idx)\n",
    "\n",
    "metadata = {\n",
    "    'vmin': global_vmin,\n",
    "    'vmax': global_vmax,\n",
    "    'patch_size': patchsize,\n",
    "    'stride': stride,\n",
    "    'min_valid': min_valid,\n",
    "    'num_patches': total_patches,\n",
    "    'file_index': [(str(f), n) for f, n in file_index]\n",
    "}\n",
    "np.save(outputdir / 'metadata.npy', metadata, allow_pickle=True)\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2a3b2db2-211d-4ffb-ba77-740495ee878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s1a-iw-grd-vh-20251114t225109-20251114t225134-061880-07bcb4-002_patches.npy: 12,705 patches\n",
      "s1a-iw-grd-vh-20260111t095455-20260111t095520-062718-07dd3c-002_patches.npy: 9,555 patches\n",
      "s1a-iw-grd-vh-20260111t233937-20260111t234002-062726-07dd91-002_patches.npy: 24,973 patches\n",
      "s1a-iw-grd-vh-20260116t113541-20260116t113606-062792-07e02d-002_patches.npy: 17,027 patches\n",
      "s1a-iw-grd-vh-20260116t231538-20260116t231603-062799-07e070-002_patches.npy: 25,054 patches\n",
      "s1a-iw-grd-vh-20260117t061452-20260117t061517-062803-07e08d-002_patches.npy: 24,027 patches\n",
      "s1a-iw-grd-vh-20260117t104141-20260117t104206-062806-07e0a7-002_patches.npy: 12,769 patches\n",
      "s1a-iw-grd-vh-20260117t104256-20260117t104321-062806-07e0a7-002_patches.npy: 25,117 patches\n",
      "s1a-iw-grd-vh-20260117t122220-20260117t122245-062807-07e0ad-002_patches.npy: 19,989 patches\n",
      "s1a-iw-grd-vh-20260117t125115-20260117t125140-062807-07e0b1-002_patches.npy: 9,304 patches\n",
      "s1a-iw-grd-vh-20260117t154520-20260117t154545-062809-07e0c2-002_patches.npy: 18,174 patches\n",
      "s1a-iw-grd-vh-20260117t172513-20260117t172538-062810-07e0cc-002_patches.npy: 20,542 patches\n",
      "s1a-iw-grd-vv-20251114t225109-20251114t225134-061880-07bcb4-001_patches.npy: 13,782 patches\n",
      "s1a-iw-grd-vv-20260111t095455-20260111t095520-062718-07dd3c-001_patches.npy: 16,124 patches\n",
      "s1a-iw-grd-vv-20260111t233937-20260111t234002-062726-07dd91-001_patches.npy: 2,573 patches\n",
      "s1a-iw-grd-vv-20260116t113541-20260116t113606-062792-07e02d-001_patches.npy: 9,247 patches\n",
      "s1a-iw-grd-vv-20260116t231538-20260116t231603-062799-07e070-001_patches.npy: 16,855 patches\n",
      "s1a-iw-grd-vv-20260117t061452-20260117t061517-062803-07e08d-001_patches.npy: 9,641 patches\n",
      "s1a-iw-grd-vv-20260117t104141-20260117t104206-062806-07e0a7-001_patches.npy: 8,240 patches\n",
      "s1a-iw-grd-vv-20260117t104256-20260117t104321-062806-07e0a7-001_patches.npy: 5,975 patches\n",
      "s1a-iw-grd-vv-20260117t122220-20260117t122245-062807-07e0ad-001_patches.npy: 8,705 patches\n",
      "s1a-iw-grd-vv-20260117t125115-20260117t125140-062807-07e0b1-001_patches.npy: 25,112 patches\n",
      "s1a-iw-grd-vv-20260117t154520-20260117t154545-062809-07e0c2-001_patches.npy: 24,012 patches\n",
      "s1a-iw-grd-vv-20260117t172513-20260117t172538-062810-07e0cc-001_patches.npy: 14,507 patches\n",
      "s1c-iw-grd-vh-20251215t084123-20251215t084148-005460-00adf4-002_patches.npy: 24,297 patches\n",
      "s1c-iw-grd-vh-20260116t173029-20260116t173054-005932-00be5a-002_patches.npy: 21,003 patches\n",
      "s1c-iw-grd-vh-20260117t052429-20260117t052454-005939-00be9c-002_patches.npy: 18,841 patches\n",
      "s1c-iw-grd-vh-20260117t052609-20260117t052634-005939-00be9c-002_patches.npy: 17,870 patches\n",
      "s1c-iw-grd-vh-20260117t052634-20260117t052659-005939-00be9c-002_patches.npy: 24,443 patches\n",
      "s1c-iw-grd-vh-20260117t090611-20260117t090636-005941-00beaf-002_patches.npy: 14,328 patches\n",
      "s1c-iw-grd-vh-20260117t180911-20260117t180936-005947-00bed8-002_patches.npy: 6,520 patches\n",
      "s1c-iw-grd-vh-20260117t203427-20260117t203452-005948-00bee7-002_patches.npy: 10,038 patches\n",
      "s1c-iw-grd-vh-20260117t225139-20260117t225204-005949-00bef3-002_patches.npy: 23,707 patches\n",
      "s1c-iw-grd-vh-20260117t225204-20260117t225229-005949-00bef3-002_patches.npy: 24,676 patches\n",
      "s1c-iw-grd-vv-20251215t084123-20251215t084148-005460-00adf4-001_patches.npy: 9,962 patches\n",
      "s1c-iw-grd-vv-20260116t173029-20260116t173054-005932-00be5a-001_patches.npy: 11,004 patches\n",
      "s1c-iw-grd-vv-20260117t052429-20260117t052454-005939-00be9c-001_patches.npy: 23,132 patches\n",
      "s1c-iw-grd-vv-20260117t052609-20260117t052634-005939-00be9c-001_patches.npy: 11,063 patches\n",
      "s1c-iw-grd-vv-20260117t052634-20260117t052659-005939-00be9c-001_patches.npy: 10,203 patches\n",
      "s1c-iw-grd-vv-20260117t090611-20260117t090636-005941-00beaf-001_patches.npy: 23,563 patches\n",
      "s1c-iw-grd-vv-20260117t180911-20260117t180936-005947-00bed8-001_patches.npy: 22,064 patches\n",
      "s1c-iw-grd-vv-20260117t203427-20260117t203452-005948-00bee7-001_patches.npy: 24,977 patches\n",
      "s1c-iw-grd-vv-20260117t225139-20260117t225204-005949-00bef3-001_patches.npy: 15,817 patches\n",
      "s1c-iw-grd-vv-20260117t225204-20260117t225229-005949-00bef3-001_patches.npy: 9,436 patches\n"
     ]
    }
   ],
   "source": [
    "# List all patch files and their sizes\n",
    "for f in sorted(outputdir.glob(\"*_patches.npy\")):\n",
    "    shape = get_npy_shape(f)\n",
    "    print(f\"{f.name}: {shape[0]:,} patches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "081e9605-297a-4137-84cb-66c97b628e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total patches: 720,953\n",
      "Global bounds: [14.77, 24.54] dB\n",
      "Patch size: 256\n",
      "Files: 44\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to read all data for array. Expected (24676, 256, 256) = 1617166336 elements, could only read 0 elements. (file seems not fully written?)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     46\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m patches\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Show random samples\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m samples = \u001b[43mload_random_patches\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m fig, axes = plt.subplots(\u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, figsize=(\u001b[32m12\u001b[39m, \u001b[32m9\u001b[39m))\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ax, patch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(axes.flatten(), samples):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 40\u001b[39m, in \u001b[36mload_random_patches\u001b[39m\u001b[34m(n)\u001b[39m\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file_idx, local_indices \u001b[38;5;129;01min\u001b[39;00m file_requests.items():\n\u001b[32m     39\u001b[39m     fpath, _ = metadata[\u001b[33m'\u001b[39m\u001b[33mfile_index\u001b[39m\u001b[33m'\u001b[39m][file_idx]\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Full load, no mmap\u001b[39;00m\n\u001b[32m     41\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m local_idx \u001b[38;5;129;01min\u001b[39;00m local_indices:\n\u001b[32m     42\u001b[39m         patches.append(data[local_idx])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\CNNAutoencoderProject\\venv\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:483\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.open_memmap(file, mode=mmap_mode,\n\u001b[32m    481\u001b[39m                                   max_header_size=max_header_size)\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    487\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Projects\\CNNAutoencoderProject\\venv\\Lib\\site-packages\\numpy\\lib\\_format_impl.py:874\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    870\u001b[39m             array[i:i + read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[32m    871\u001b[39m                                                      count=read_count)\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m array.size != count:\n\u001b[32m--> \u001b[39m\u001b[32m874\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    875\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFailed to read all data for array. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    876\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elements, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    877\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcould only read \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elements. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    878\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m(file seems not fully written?)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    879\u001b[39m     )\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fortran_order:\n\u001b[32m    882\u001b[39m     array = array.reshape(shape[::-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mValueError\u001b[39m: Failed to read all data for array. Expected (24676, 256, 256) = 1617166336 elements, could only read 0 elements. (file seems not fully written?)"
     ]
    }
   ],
   "source": [
    "# Cell 6: Verify\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load metadata\n",
    "metadata = np.load(outputdir / 'metadata.npy', allow_pickle=True).item()\n",
    "shuffle_idx = np.load(outputdir / \"shuffle_idx.npy\")\n",
    "\n",
    "print(f\"Total patches: {metadata['num_patches']:,}\")\n",
    "print(f\"Global bounds: [{metadata['vmin']:.2f}, {metadata['vmax']:.2f}] dB\")\n",
    "print(f\"Patch size: {metadata['patch_size']}\")\n",
    "print(f\"Files: {len(metadata['file_index'])}\")\n",
    "\n",
    "# Load a few random patches for visualization\n",
    "def load_random_patches(n=12):\n",
    "    \"\"\"Load n random patches from the dataset\"\"\"\n",
    "    patches = []\n",
    "    \n",
    "    # Build cumsum for file lookup\n",
    "    cumsum = [0]\n",
    "    for _, count in metadata['file_index']:\n",
    "        cumsum.append(cumsum[-1] + count)\n",
    "    \n",
    "    random_indices = np.random.choice(len(shuffle_idx), n, replace=False)\n",
    "    \n",
    "    # Group by file to minimize loads\n",
    "    file_requests = {}\n",
    "    for idx in random_indices:\n",
    "        real_idx = shuffle_idx[idx]\n",
    "        for i, (start, end) in enumerate(zip(cumsum[:-1], cumsum[1:])):\n",
    "            if start <= real_idx < end:\n",
    "                local_idx = real_idx - start\n",
    "                if i not in file_requests:\n",
    "                    file_requests[i] = []\n",
    "                file_requests[i].append(local_idx)\n",
    "                break\n",
    "    \n",
    "    # Load from each file\n",
    "    for file_idx, local_indices in file_requests.items():\n",
    "        fpath, _ = metadata['file_index'][file_idx]\n",
    "        data = np.load(fpath)  # Full load, no mmap\n",
    "        for local_idx in local_indices:\n",
    "            patches.append(data[local_idx])\n",
    "        del data\n",
    "        gc.collect()\n",
    "    \n",
    "    return patches\n",
    "\n",
    "# Show random samples\n",
    "samples = load_random_patches(12)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 9))\n",
    "for ax, patch in zip(axes.flatten(), samples):\n",
    "    ax.imshow(patch, cmap='gray', vmin=0, vmax=1)\n",
    "    ax.axis('off')\n",
    "plt.suptitle(f\"Random samples from {metadata['num_patches']:,} patches\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b149d2f5-3ba5-477d-bd58-3ff57e0d92d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
