{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 2: Architecture Deep Dive\n",
    "\n",
    "**Goals:**\n",
    "- Thoroughly understand your existing architecture\n",
    "- Verify shapes, gradients, and parameter counts\n",
    "- Implement skip connections and residual blocks (if missing)\n",
    "\n",
    "**Time:** 6 hours\n",
    "\n",
    "**Approach:** Instructions only. Write all code yourself.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Import PyTorch and its nn module. Also import numpy and matplotlib. Set up your device (CUDA if available, else CPU) and print which device you're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your imports and device setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import your model modules from `src/models/`. Try to import your autoencoder, encoder, decoder, and blocks modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your model modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Theory Questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.1: Parameter Counting\n",
    "\n",
    "Consider a convolutional layer: `Conv2d(in_channels=64, out_channels=128, kernel_size=3, bias=True)`\n",
    "\n",
    "**a)** Calculate the exact number of parameters. Show your formula and arithmetic.\n",
    "\n",
    "**b)** If the input spatial size is 64×64, how many multiply-accumulate operations does this layer perform? (Each output pixel requires kernel_size² × in_channels multiplications, summed across all output channels and spatial positions.)\n",
    "\n",
    "**c)** If you add `groups=2`, how does this change the parameter count? What does grouped convolution do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "**a)** Formula: \n",
    "\n",
    "Calculation:\n",
    "\n",
    "**b)**\n",
    "\n",
    "**c)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.2: Shape Propagation\n",
    "\n",
    "Trace the tensor shape through this sequence of layers. Start with input shape (batch=8, channels=1, height=256, width=256).\n",
    "\n",
    "```python\n",
    "Conv2d(1, 64, kernel_size=7, stride=2, padding=3)\n",
    "Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "Conv2d(256, 64, kernel_size=3, stride=2, padding=1)\n",
    "```\n",
    "\n",
    "Use the output size formula: `out = floor((in + 2×padding - kernel_size) / stride) + 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "After layer 1: (8, ?, ?, ?)\n",
    "\n",
    "After layer 2: \n",
    "\n",
    "After layer 3: \n",
    "\n",
    "After layer 4: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.3: Receptive Field\n",
    "\n",
    "Your encoder uses 4 convolutional layers, each with kernel_size=4, stride=2, padding=1.\n",
    "\n",
    "**a)** Calculate the receptive field after each layer. The formula for layer n is:\n",
    "```\n",
    "RF_n = RF_{n-1} + (kernel_size - 1) × stride_product_{n-1}\n",
    "```\n",
    "where stride_product is the product of all previous strides.\n",
    "\n",
    "**b)** Your 256×256 input maps to a 16×16 latent space. Each latent \"pixel\" should ideally \"see\" a 16×16 region of the input. Is your receptive field sufficient?\n",
    "\n",
    "**c)** How could you increase the receptive field without adding more layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "**a)** \n",
    "\n",
    "Layer 0 (input): RF = 1\n",
    "\n",
    "Layer 1: RF = \n",
    "\n",
    "Layer 2: RF = \n",
    "\n",
    "Layer 3: RF = \n",
    "\n",
    "Layer 4: RF = \n",
    "\n",
    "**b)**\n",
    "\n",
    "**c)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.4: Skip Connections\n",
    "\n",
    "**a)** What information do skip connections preserve that would otherwise be lost passing through the bottleneck?\n",
    "\n",
    "**b)** For an autoencoder used for *compression* (not denoising), are skip connections helpful or harmful? Why?\n",
    "\n",
    "**c)** If you have skip connections, how could you quantify how much information is \"bypassing\" the bottleneck versus going through it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "**a)**\n",
    "\n",
    "**b)**\n",
    "\n",
    "**c)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2.5: Activation Functions\n",
    "\n",
    "**a)** Why use LeakyReLU(0.2) instead of ReLU in autoencoders? What problem does it address?\n",
    "\n",
    "**b)** What is the gradient of LeakyReLU(0.2) for x < 0? Compare to ReLU.\n",
    "\n",
    "**c)** Why use Sigmoid at the output layer when your target is normalized to [0, 1]? What would happen if you used no activation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Answer:\n",
    "\n",
    "**a)**\n",
    "\n",
    "**b)**\n",
    "\n",
    "**c)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Analyze Your Architecture (1.5 hours)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.1: Instantiate and Count Parameters\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Instantiate your autoencoder model (check your `src/models/autoencoder.py` for the class name and required arguments).\n",
    "\n",
    "2. Move it to your device.\n",
    "\n",
    "3. Count total parameters using: `sum(p.numel() for p in model.parameters())`\n",
    "\n",
    "4. Count trainable parameters by adding `if p.requires_grad` to the above.\n",
    "\n",
    "5. Print both counts formatted with commas for readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and count parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2: Layer-by-Layer Breakdown\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Iterate through `model.named_modules()` to get each layer.\n",
    "\n",
    "2. For each Conv2d and ConvTranspose2d layer, print:\n",
    "   - The layer name\n",
    "   - The parameter count for that layer\n",
    "   - Input/output channels and kernel size (access via `module.in_channels`, etc.)\n",
    "\n",
    "3. Identify which layers have the most parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print layer-by-layer breakdown\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.3: Shape Verification\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Create a random input tensor with shape (4, 1, 256, 256) on your device.\n",
    "\n",
    "2. Pass it through your model to get the output.\n",
    "\n",
    "3. Print both input and output shapes.\n",
    "\n",
    "4. Assert that they match exactly. If they don't, investigate why.\n",
    "\n",
    "5. Check the output range - if your model uses Sigmoid, values should be in [0, 1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.4: Gradient Flow Test\n",
    "\n",
    "This is crucial - if gradients don't flow properly, your model won't train.\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Put the model in training mode with `model.train()`.\n",
    "\n",
    "2. Create an input tensor with `requires_grad=True`.\n",
    "\n",
    "3. Forward pass through the model.\n",
    "\n",
    "4. Compute a simple loss (e.g., sum of output).\n",
    "\n",
    "5. Call `loss.backward()`.\n",
    "\n",
    "6. Check every parameter with `model.named_parameters()`:\n",
    "   - Is `param.grad` None? (Bad - no gradient reached this parameter)\n",
    "   - Is `param.grad.abs().max()` very small (< 1e-10)? (Concerning - vanishing gradient)\n",
    "   - Does `param.grad` contain NaN? (Bad - numerical instability)\n",
    "\n",
    "7. Print any problematic layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient flow test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.5: Trace Shapes Through Network\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "This is a debugging exercise. You'll manually trace a tensor through your encoder to see shapes at each stage.\n",
    "\n",
    "1. Create an input tensor (1, 1, 256, 256).\n",
    "\n",
    "2. Access your encoder (might be `model.encoder` or similar).\n",
    "\n",
    "3. Manually pass the tensor through each layer/block in the encoder, printing the shape after each one.\n",
    "\n",
    "4. Do the same for the decoder, starting from the latent.\n",
    "\n",
    "This helps you understand exactly what each layer does to the tensor dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace shapes through encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace shapes through decoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 3: Implement/Verify Skip Connections (1.5 hours)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.6: Check for Existing Skip Connections\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Open your `src/models/encoder.py` and `src/models/decoder.py`.\n",
    "\n",
    "2. Answer these questions by reading the code:\n",
    "   - Does your encoder's `forward()` method return just the latent, or does it also return intermediate features?\n",
    "   - Does your decoder's `forward()` method accept skip connections as an argument?\n",
    "   - If skip connections exist, how are they combined? (concatenation? addition?)\n",
    "\n",
    "Document what you find below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Findings:\n",
    "\n",
    "**Encoder output:**\n",
    "\n",
    "**Decoder input:**\n",
    "\n",
    "**Skip connection method (if any):**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.7: Implement Encoder with Skip Outputs\n",
    "\n",
    "If your encoder doesn't already return skip connections, implement a version that does.\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Create a class `EncoderWithSkips` that:\n",
    "\n",
    "1. Has the same layer structure as your current encoder.\n",
    "\n",
    "2. In `forward()`, stores the output of each downsampling stage before applying the next one.\n",
    "\n",
    "3. Returns a tuple: `(latent, [skip1, skip2, skip3, ...])`\n",
    "\n",
    "The skip connections should be in order from highest resolution to lowest (but not including the latent itself).\n",
    "\n",
    "Test it by passing a tensor through and printing all output shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement EncoderWithSkips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.8: Implement Decoder with Skip Inputs\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Create a class `DecoderWithSkips` that:\n",
    "\n",
    "1. Accepts `forward(latent, skips)` where skips is the list from your encoder.\n",
    "\n",
    "2. At each upsampling stage, concatenates the upsampled features with the corresponding skip connection along the channel dimension using `torch.cat([upsampled, skip], dim=1)`.\n",
    "\n",
    "3. Adjusts the input channels of each layer to account for the concatenated skip features.\n",
    "\n",
    "**Important:** The skip from encoder stage n (counting from input) should connect to decoder stage n (counting from output). Make sure resolutions match!\n",
    "\n",
    "Test by passing the encoder outputs through and verifying the final output shape matches the original input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement DecoderWithSkips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the full encoder-decoder with skips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 4: Implement/Verify Residual Blocks (1 hour)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.9: Check for Existing Residual Blocks\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Check your `src/models/blocks.py` for a ResidualBlock or similar class.\n",
    "\n",
    "If it exists, note:\n",
    "- What layers are in the residual path?\n",
    "- Is batch normalization used?\n",
    "- What activation function is used?\n",
    "- Is the skip connection a simple addition, or does it have a projection?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your Findings:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.10: Implement a Residual Block\n",
    "\n",
    "If you don't have one, or want to understand how they work, implement a basic residual block.\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "Create a class `ResidualBlock(nn.Module)` that:\n",
    "\n",
    "1. Takes `channels` as a constructor argument (input channels = output channels for a basic block).\n",
    "\n",
    "2. Contains two conv layers with same padding (so spatial dimensions don't change).\n",
    "\n",
    "3. Uses BatchNorm2d after each convolution.\n",
    "\n",
    "4. Uses LeakyReLU(0.2) as activation.\n",
    "\n",
    "5. In `forward()`, computes `output = activation(x + F(x))` where F is the conv-bn-activation-conv-bn path.\n",
    "\n",
    "Test that input and output shapes match, and that gradients flow through."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement ResidualBlock\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.11: Compare Parameters\n",
    "\n",
    "**Your task:**\n",
    "\n",
    "1. Count parameters in a single ResidualBlock with 64 channels.\n",
    "\n",
    "2. If you add one ResidualBlock after each encoder/decoder stage (8 total), how many parameters does this add?\n",
    "\n",
    "3. What percentage increase is this compared to your base model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Day 2 Checklist\n",
    "\n",
    "- [ ] Answered all theory questions (Q2.1 - Q2.5)\n",
    "- [ ] Counted total and trainable parameters\n",
    "- [ ] Generated layer-by-layer parameter breakdown\n",
    "- [ ] Verified input/output shapes match\n",
    "- [ ] Verified gradient flow to all parameters\n",
    "- [ ] Traced shapes through encoder and decoder manually\n",
    "- [ ] Documented existing skip connection implementation (or lack thereof)\n",
    "- [ ] Implemented/verified EncoderWithSkips\n",
    "- [ ] Implemented/verified DecoderWithSkips\n",
    "- [ ] Implemented/verified ResidualBlock\n",
    "- [ ] Compared parameter counts with/without additions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture Summary\n",
    "\n",
    "*Fill this in based on your analysis:*\n",
    "\n",
    "**Total parameters:**\n",
    "\n",
    "**Input shape:** (B, 1, 256, 256)\n",
    "\n",
    "**Latent shape:**\n",
    "\n",
    "**Compression ratio:**\n",
    "\n",
    "**Has skip connections:** Yes / No\n",
    "\n",
    "**Has residual blocks:** Yes / No\n",
    "\n",
    "**Output activation:** Sigmoid / None / Other\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes and Issues\n",
    "\n",
    "1. \n",
    "\n",
    "2. \n",
    "\n",
    "3. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
