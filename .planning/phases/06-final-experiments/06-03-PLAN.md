---
phase: 06-final-experiments
plan: 03
type: execute
wave: 3
depends_on: [06-02]
files_modified:
  - reports/final_comparison.ipynb
  - reports/final_comparison.md
  - reports/figures/rate_distortion_psnr.png
  - reports/figures/rate_distortion_ssim.png
  - reports/figures/visual_comparison_*.png
  - reports/tables/statistical_tests.csv
autonomous: true

must_haves:
  truths:
    - "Rate-distortion curves show PSNR vs BPP for all methods"
    - "Statistical tests compare autoencoder vs JPEG-2000 with p-values"
    - "Visual comparison gallery shows 5 examples per compression ratio"
    - "Final report summarizes findings with conclusions"
  artifacts:
    - path: "reports/final_comparison.ipynb"
      provides: "Reproducible analysis notebook"
    - path: "reports/final_comparison.md"
      provides: "Readable markdown report"
    - path: "reports/figures/rate_distortion_psnr.png"
      provides: "PSNR vs BPP curve"
    - path: "reports/figures/rate_distortion_ssim.png"
      provides: "SSIM vs BPP curve"
    - path: "reports/figures/visual_comparison_16x.png"
      provides: "Visual examples at 16x compression"
    - path: "reports/tables/statistical_tests.csv"
      provides: "Statistical test results"
  key_links:
    - from: "reports/final_comparison.ipynb"
      to: "reports/data/per_sample_metrics.json"
      via: "JSON load for statistical tests"
      pattern: "per_sample_metrics"
    - from: "reports/final_comparison.ipynb"
      to: "scipy.stats"
      via: "ttest_rel, wilcoxon imports"
      pattern: "from scipy.stats import"
---

<objective>
Generate comprehensive analysis with rate-distortion curves, statistical tests, visual comparisons, and final report.

Purpose: Transform raw evaluation data into publishable results that demonstrate autoencoder performance vs JPEG-2000.

Output: Complete analysis notebook, markdown report, publication-quality figures, and statistical test results.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/06-final-experiments/06-CONTEXT.md
@.planning/phases/06-final-experiments/06-RESEARCH.md
@src/evaluation/visualizer.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create analysis notebook with rate-distortion curves</name>
  <files>reports/final_comparison.ipynb, reports/figures/rate_distortion_psnr.png, reports/figures/rate_distortion_ssim.png</files>
  <action>
Create Jupyter notebook `reports/final_comparison.ipynb` with the following sections:

**1. Setup and Data Loading**
```python
import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import ttest_rel, wilcoxon, shapiro

# Publication-quality figure settings
plt.rcParams.update({
    'font.size': 10, 'font.family': 'serif',
    'figure.figsize': (8, 5), 'figure.dpi': 150,
    'savefig.dpi': 300, 'savefig.bbox': 'tight',
})

# Load evaluation data
with open('data/all_results.json') as f:
    all_results = json.load(f)
with open('data/per_sample_metrics.json') as f:
    per_sample = json.load(f)
summary_df = pd.read_csv('tables/results_summary.csv')
```

**2. Rate-Distortion Curves**
- PSNR vs BPP (bits per pixel) - separate curves for Baseline, ResNet, JPEG-2000
- SSIM vs BPP - same grouping
- Use markers: 'o' for Baseline, 's' for ResNet, '^' for JPEG-2000
- Colors: blue for Baseline, orange for ResNet, gray for JPEG-2000
- Add legend, grid, axis labels
- Save to `figures/rate_distortion_psnr.png` and `figures/rate_distortion_ssim.png`

**3. Summary Table**
- Model name, compression ratio, PSNR mean/std, SSIM mean/std
- Sorted by compression ratio, then by model type
- Export to CSV and display as formatted table

Use existing `Visualizer.plot_rate_distortion()` as reference but customize for publication quality.
  </action>
  <verify>
Notebook cells execute without error:
```bash
cd reports && jupyter nbconvert --execute final_comparison.ipynb --to html --output /dev/null
```
Figures exist: `reports/figures/rate_distortion_psnr.png`, `reports/figures/rate_distortion_ssim.png`
  </verify>
  <done>Rate-distortion curves generated and saved as PNG</done>
</task>

<task type="auto">
  <name>Task 2: Perform statistical analysis</name>
  <files>reports/tables/statistical_tests.csv, reports/final_comparison.ipynb (updated)</files>
  <action>
Add statistical analysis section to the notebook:

**Statistical Comparison: Autoencoder vs JPEG-2000**

For each compression ratio (4x, 8x, 16x), compare best autoencoder to JPEG-2000:

```python
def compare_methods(ae_samples: list, codec_samples: list, metric: str = 'psnr'):
    """Paired statistical test between autoencoder and codec."""
    ae_vals = np.array([s[metric] for s in ae_samples])
    codec_vals = np.array([s[metric] for s in codec_samples])
    diff = ae_vals - codec_vals

    # Check normality
    _, p_normal = shapiro(diff[:50])  # Shapiro limited to ~50 samples

    # Select appropriate test
    if p_normal > 0.05:
        stat, p_value = ttest_rel(ae_vals, codec_vals)
        test_name = "paired t-test"
    else:
        stat, p_value = wilcoxon(ae_vals, codec_vals)
        test_name = "Wilcoxon"

    return {
        'test': test_name,
        'statistic': stat,
        'p_value': p_value,
        'ae_mean': np.mean(ae_vals),
        'codec_mean': np.mean(codec_vals),
        'difference': np.mean(diff),
        'significant': p_value < 0.05
    }
```

Run comparisons:
- ResNet vs JPEG-2000 at each ratio (primary comparison)
- Baseline vs JPEG-2000 at each ratio (secondary)
- Report PSNR and SSIM differences with p-values

Apply Bonferroni correction if testing multiple metrics (divide alpha by number of tests).

Save results to `tables/statistical_tests.csv` with columns:
- ratio, model_vs_codec, metric, ae_mean, codec_mean, difference, test, p_value, significant
  </action>
  <verify>Statistical tests CSV exists with columns: ratio, model_vs_codec, metric, p_value, significant</verify>
  <done>Statistical tests complete with Bonferroni correction applied</done>
</task>

<task type="auto">
  <name>Task 3: Generate visual comparison gallery and final report</name>
  <files>reports/figures/visual_comparison_*.png, reports/final_comparison.md</files>
  <action>
**Visual Comparison Gallery**

Create 3-column comparison images (Original | Best Autoencoder | JPEG-2000) at each compression ratio:

```python
from src.evaluation import Visualizer

# Select 5 representative samples per ratio
# Include: 1 urban, 1 water, 1 forest, 1 agricultural, 1 mixed

for ratio in [4, 8, 16]:
    # Get best autoencoder at this ratio (ResNet if available, else Baseline)
    # Load test images
    # Generate comparison grid with error heatmaps

    fig, axes = plt.subplots(5, 4, figsize=(16, 20))
    # Col 0: Original
    # Col 1: Autoencoder reconstruction
    # Col 2: JPEG-2000 reconstruction
    # Col 3: Error heatmap (autoencoder - JPEG-2000 difference)

    plt.savefig(f'figures/visual_comparison_{ratio}x.png', dpi=300)
```

**Final Markdown Report**

Export notebook to markdown and add executive summary:

```markdown
# SAR Image Compression: Autoencoder vs JPEG-2000 Comparison Study

## Executive Summary
[Brief findings: does autoencoder beat JPEG-2000? At which ratios? By how much?]

## Rate-Distortion Analysis
[Include R-D curve figures with interpretation]

## Statistical Significance
[Key findings from paired tests]

## Visual Comparison
[Gallery references with observations about quality differences]

## Conclusions
[Primary findings, limitations, future work]
```

Convert notebook to markdown: `jupyter nbconvert --to markdown final_comparison.ipynb`
  </action>
  <verify>
Visual comparisons exist: `reports/figures/visual_comparison_16x.png`
Markdown report exists: `reports/final_comparison.md` with sections for Summary, Analysis, Conclusions
  </verify>
  <done>Visual gallery and final report complete</done>
</task>

</tasks>

<verification>
1. Notebook executes: `reports/final_comparison.ipynb`
2. R-D curves: `reports/figures/rate_distortion_psnr.png`, `reports/figures/rate_distortion_ssim.png`
3. Statistical tests: `reports/tables/statistical_tests.csv` with p-values
4. Visual gallery: `reports/figures/visual_comparison_16x.png` (and 4x, 8x)
5. Final report: `reports/final_comparison.md` with executive summary
</verification>

<success_criteria>
- Rate-distortion curves clearly show performance of all methods
- Statistical tests determine if autoencoder significantly outperforms JPEG-2000
- Visual gallery demonstrates quality differences with error heatmaps
- Final report is publication-ready with clear conclusions
- All figures are 300 DPI with proper fonts and labels
</success_criteria>

<output>
After completion, create `.planning/phases/06-final-experiments/06-03-SUMMARY.md`
</output>
