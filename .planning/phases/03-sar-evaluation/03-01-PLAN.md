---
phase: 03-sar-evaluation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/evaluation/metrics.py
autonomous: true

must_haves:
  truths:
    - "ENL ratio computes correctly on homogeneous regions, returning values 0.5-2.0"
    - "EPI computes correctly as gradient correlation, returning values near 1.0 for good reconstructions"
    - "MS-SSIM computes for 256x256 patches without NaN errors"
    - "Histogram similarity returns intersection, chi-square, and Bhattacharyya metrics"
  artifacts:
    - path: "src/evaluation/metrics.py"
      provides: "Complete SAR-specific metrics implementation"
      exports: ["SARMetrics", "find_homogeneous_regions", "compute_enl", "enl_ratio", "edge_preservation_index", "compute_ms_ssim", "histogram_similarity"]
      min_lines: 250
  key_links:
    - from: "src/evaluation/metrics.py"
      to: "scipy.ndimage"
      via: "uniform_filter, sobel"
      pattern: "ndimage\\.(uniform_filter|sobel)"
    - from: "src/evaluation/metrics.py"
      to: "pytorch_msssim"
      via: "ms_ssim function"
      pattern: "from pytorch_msssim import ms_ssim"
---

<objective>
Implement core SAR-specific quality metrics in metrics.py: ENL ratio with homogeneous region detection, Edge Preservation Index as gradient correlation, MS-SSIM integration, and enhanced histogram similarity.

Purpose: These metrics are foundational for evaluating SAR autoencoder quality beyond standard PSNR/SSIM. ENL ratio measures speckle preservation, EPI measures edge fidelity, and histogram similarity measures intensity distribution preservation.

Output: Complete `src/evaluation/metrics.py` with all metric stubs replaced by working implementations.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-sar-evaluation/03-RESEARCH.md
@.planning/phases/03-sar-evaluation/03-CONTEXT.md
@src/evaluation/metrics.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement ENL ratio with homogeneous region detection</name>
  <files>src/evaluation/metrics.py</files>
  <action>
Implement ENL ratio computation with coefficient of variation (CV) based homogeneous region detection.

Add these functions (reference RESEARCH.md Pattern 1):

1. `find_homogeneous_regions(image, window_size=15, cv_threshold=0.3)` -> np.ndarray (boolean mask)
   - Use scipy.ndimage.uniform_filter for local mean/variance
   - CV = local_std / local_mean
   - Return mask where CV < cv_threshold

2. `compute_enl(image, mask)` -> float
   - ENL = mu^2 / sigma^2 in masked regions
   - Return np.nan if mask.sum() < 100 (not enough samples)

3. `enl_ratio(original, reconstructed, window_size=15, cv_threshold=0.3)` -> dict
   - Find homogeneous regions in original image
   - Compute ENL for both original and reconstructed using same mask
   - Return dict with:
     - enl_original: float
     - enl_reconstructed: float
     - enl_ratio: enl_recon / enl_orig
     - homogeneous_pixels: int
     - homogeneous_fraction: float

Per CONTEXT.md: Support both linear intensity and dB domain computation. Add optional `domain` parameter ('db' or 'linear', default 'db' since data is already in dB).

Replace the existing stub `enl()` method in SARMetrics class with proper implementation using these functions.
  </action>
  <verify>
Run test in Python:
```python
import numpy as np
from src.evaluation.metrics import enl_ratio, find_homogeneous_regions
# Create synthetic homogeneous region
img = np.random.rand(256, 256) * 0.1 + 0.5  # Low variance
result = enl_ratio(img, img * 0.99)  # Slight perturbation
assert 0.8 < result['enl_ratio'] < 1.2
assert result['homogeneous_fraction'] > 0.1
print(f"ENL ratio: {result['enl_ratio']:.3f}, homogeneous fraction: {result['homogeneous_fraction']:.3f}")
```
  </verify>
  <done>
ENL ratio function returns dict with enl_original, enl_reconstructed, enl_ratio, homogeneous_pixels, homogeneous_fraction. Homogeneous detection uses CV threshold.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement EPI as gradient correlation and other metrics</name>
  <files>src/evaluation/metrics.py</files>
  <action>
Implement Edge Preservation Index as gradient magnitude CORRELATION (not ratio), plus histogram similarity and MS-SSIM.

1. Update `edge_preservation_index(x, x_hat)` -> float:
   - Compute gradient magnitude using scipy.ndimage.sobel
   - Return CORRELATION of gradient magnitudes (reference RESEARCH.md Pattern 2)
   - Formula: sum(go * gr) / sqrt(sum(go^2) * sum(gr^2))
   - This gives EPI in range [0, 1], where 1 = perfect edge preservation
   - NOTE: This differs from the ratio formula in evaluator.py; correlation is more robust

2. Update `histogram_similarity(x, x_hat, bins=256)` -> dict:
   - Compute histograms with density=True, range=(0,1)
   - Return dict with:
     - intersection: float (1 = identical)
     - chi_square: float (0 = identical)
     - bhattacharyya: float (1 = identical)

3. Add `compute_ms_ssim(original, reconstructed, data_range=1.0)` -> float:
   - Use pytorch_msssim.ms_ssim
   - Convert numpy arrays to torch tensors (1, 1, H, W)
   - Handle edge case: images must be >= 160x160 for default 5-scale MS-SSIM
   - Return NaN if images too small, with warning

4. Update `local_variance_ratio(x, x_hat, window_size=16)` -> dict:
   - Compute local variance maps using uniform_filter
   - Return variance_ratio and variance_correlation

Replace all stubs (NotImplementedError) with working implementations.
  </action>
  <verify>
Run comprehensive test:
```python
import numpy as np
from src.evaluation.metrics import SARMetrics, compute_ms_ssim, histogram_similarity

# Test data
np.random.seed(42)
orig = np.random.rand(256, 256).astype(np.float32)
recon = np.clip(orig + 0.05 * np.random.randn(256, 256), 0, 1).astype(np.float32)

# Test EPI (correlation version)
epi = SARMetrics.edge_preservation_index(orig, recon)
assert 0 < epi <= 1.0, f"EPI should be in (0, 1], got {epi}"
print(f"EPI: {epi:.4f}")

# Test histogram similarity
hist = histogram_similarity(orig, recon)
assert 'intersection' in hist and 'chi_square' in hist and 'bhattacharyya' in hist
print(f"Histogram: intersection={hist['intersection']:.3f}")

# Test MS-SSIM
ms = compute_ms_ssim(orig, recon)
assert 0 < ms <= 1.0, f"MS-SSIM should be in (0, 1], got {ms}"
print(f"MS-SSIM: {ms:.4f}")

# Test local variance ratio
lvr = SARMetrics.local_variance_ratio(orig, recon)
assert 'variance_ratio' in lvr and 'variance_correlation' in lvr
print(f"Variance ratio: {lvr['variance_ratio']:.4f}")

print("All metric tests passed!")
```
  </verify>
  <done>
EPI returns correlation value in [0, 1]. histogram_similarity returns dict with 3 metrics. compute_ms_ssim works for 256x256. local_variance_ratio returns dict with ratio and correlation. No NotImplementedError remains in metrics.py.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add compression metrics and update module exports</name>
  <files>src/evaluation/metrics.py</files>
  <action>
Add compression ratio and BPP calculation functions, plus clean up module.

1. Add `compute_compression_ratio(original_size, compressed_size)` -> float:
   - Simple ratio: original_size / compressed_size
   - For autoencoder: original is H*W*1*32 (float32 bits), compressed is latent_h*latent_w*channels*32

2. Add `compute_bpp(original_shape, compressed_bits)` -> float:
   - BPP = compressed_bits / (H * W)
   - For autoencoder: compressed_bits = latent_size * 32 (float32)
   - For traditional codecs: compressed_bits = len(encoded_bytes) * 8

3. Add `compute_all_metrics(original, reconstructed, data_range=1.0)` -> dict:
   - Convenience function computing all metrics in one call
   - Returns dict with: mse, psnr, ssim, ms_ssim, epi, enl_ratio (full dict), histogram (full dict), local_variance (full dict), correlation (full dict)
   - Use try/except for MS-SSIM to handle edge cases

4. Update SARMetrics class:
   - Ensure all static methods work correctly
   - Add clear docstrings per knowledge docs
   - Add type hints

5. Update test_metrics() function to test all new functionality

6. Ensure __all__ exports appropriate symbols if using explicit exports
  </action>
  <verify>
Run the built-in test:
```bash
cd D:\Projects\CNNAutoencoderProject
python -c "from src.evaluation.metrics import compute_all_metrics, compute_compression_ratio, compute_bpp; import numpy as np; orig = np.random.rand(256, 256).astype(np.float32); recon = np.clip(orig + 0.03 * np.random.randn(256, 256), 0, 1).astype(np.float32); m = compute_all_metrics(orig, recon); print('PSNR:', m['psnr'], 'SSIM:', m['ssim'], 'EPI:', m['epi']); print('ENL ratio:', m['enl_ratio']['enl_ratio']); cr = compute_compression_ratio(256*256*4, 16*16*16*4); print('Compression ratio:', cr); bpp = compute_bpp((256, 256), 16*16*16*32); print('BPP:', bpp)"
```

Also run the module's built-in test:
```bash
cd D:\Projects\CNNAutoencoderProject
python -m src.evaluation.metrics
```
  </verify>
  <done>
compute_compression_ratio and compute_bpp calculate correctly. compute_all_metrics returns comprehensive dict with all metrics. test_metrics() passes. Module can be imported without errors.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. All stubs replaced - no NotImplementedError in metrics.py
2. `python -m src.evaluation.metrics` runs without errors
3. Import test: `from src.evaluation.metrics import SARMetrics, enl_ratio, compute_ms_ssim, compute_all_metrics, compute_bpp`
4. ENL ratio returns expected structure with homogeneous region info
5. EPI uses correlation formula (returns value in [0, 1])
</verification>

<success_criteria>
1. ENL ratio computes with CV-based homogeneous detection, returns values 0.8-1.2 for similar images
2. EPI uses gradient correlation formula, returns ~0.9-1.0 for similar images
3. MS-SSIM computes without NaN for 256x256 images
4. histogram_similarity returns intersection, chi_square, bhattacharyya
5. compute_all_metrics returns comprehensive dict with all metrics
6. No stubs remain (grep for NotImplementedError returns nothing)
</success_criteria>

<output>
After completion, create `.planning/phases/03-sar-evaluation/03-01-SUMMARY.md`
</output>
