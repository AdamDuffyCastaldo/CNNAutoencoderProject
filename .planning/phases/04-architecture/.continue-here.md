---
phase: 04-architecture
task: training-sweeps
total_tasks: 2
status: in_progress
last_updated: 2026-01-27
---

<current_state>
Training sweep infrastructure is complete. Notebooks and scripts are ready to run.
User attempted first sweep run but interrupted it (epoch took too long at 20% data).
Reduced to 10% data / 35 epochs across all configs. tqdm progress bars in trainer.py
were switched to `tqdm.notebook` to render in Jupyter but user reports they still
don't display — this is a minor UX issue, not a blocker (training still runs fine).
</current_state>

<completed_work>

## Previous Session
- Reviewed overnight training results — all non-baseline models regressed
- Standardized naming convention across all training notebooks
- Identified root causes: LR too high, OneCycleLR, small base_channels

## This Session
1. Created `scripts/train_sweep.py` — CLI script with single-run and YAML sweep modes
2. Created `configs/sweep_baseline_ratios.yaml` — baseline at 3 compression ratios (4x, 8x, ~12x)
3. Created `configs/sweep_all_16x.yaml` — all 4 architectures at 16x compression
4. Created `notebooks/sweep_baseline_ratios.ipynb` — Jupyter version with tqdm + TensorBoard
5. Created `notebooks/sweep_all_16x.ipynb` — Jupyter version for architecture comparison
6. Fixed `notebooks/compare_architectures.ipynb`:
   - Corrected checkpoint paths (added `notebooks/checkpoints` prefix)
   - Fixed attention checkpoint path (`attention_v2_quick_c16/best.pth`)
   - Added datestamps to saved PNG and JSON filenames
   - Changed to random image sampling instead of sequential batch
7. Reviewed `notebooks/train_resnet.ipynb` — identified 6 hyperparameter issues
8. All configs standardized to: TRAIN_SUBSET=0.10, EPOCHS=35, EARLY_STOPPING_PATIENCE=12
9. Trainer tqdm changed to `from tqdm.notebook import tqdm` (still not rendering in VS Code)

</completed_work>

<remaining_work>

- Task 1: Run baseline ratios sweep (3 runs: LC=64/32/21 at 4x/8x/~12x compression)
  - Use notebook: `notebooks/sweep_baseline_ratios.ipynb`
  - Or CLI: `python scripts/train_sweep.py --sweep configs/sweep_baseline_ratios.yaml`
- Task 2: Run architecture comparison sweep (4 runs: baseline/resnet/residual/attention at 16x)
  - Use notebook: `notebooks/sweep_all_16x.ipynb`
  - Or CLI: `python scripts/train_sweep.py --sweep configs/sweep_all_16x.yaml`
- After sweeps: analyze results, pick best architecture, update STATE.md metrics

</remaining_work>

<decisions_made>

- TRAIN_SUBSET=0.10 (10% of 696K patches = ~63K train) — balances speed vs quality
- EPOCHS=35 with EARLY_STOPPING_PATIENCE=12 — enough to converge but not waste time
- LR=1e-4 with AdamW + ReduceLROnPlateau — proven config from baseline (20.47 dB)
- OneCycleLR banned — caused regressions in all previous overnight runs
- Baseline compression ratios: 4x (LC=64), 8x (LC=32), ~12x (LC=21)
- Attention model uses base_channels=48 (others use 64) due to higher per-block param count
- tqdm.notebook in trainer.py for Jupyter rendering (was tqdm terminal version)

</decisions_made>

<blockers>

- tqdm progress bars not rendering in VS Code Jupyter — minor UX issue, does not block training
  - Tried: tqdm.auto, tqdm.notebook — neither renders in VS Code
  - Workaround: monitor via TensorBoard (`tensorboard --logdir=runs`) or run via CLI script
  - May need VS Code Jupyter extension update or different ipywidgets version

</blockers>

<context>
Phase 4 is 83% complete — all model architectures are implemented and tested,
but only baseline@16x has a good checkpoint (20.47 dB). All other models regressed
due to bad hyperparameters (LR too high, OneCycleLR, small base_channels).

The sweep infrastructure was built this session to systematically retrain everything
with proven settings. Two sweeps need to run:
1. Baseline at multiple compression ratios -> rate-distortion curves
2. All architectures at 16x -> fair architecture comparison

Each sweep is ~3-4 runs, each run trains for up to 35 epochs on 10% data.
Best approach is to run overnight via CLI script for reliability.
</context>

<next_action>
Run the baseline ratios sweep first:
```bash
python scripts/train_sweep.py --sweep configs/sweep_baseline_ratios.yaml
```
Or open `notebooks/sweep_baseline_ratios.ipynb` and run all cells.

Monitor with: `tensorboard --logdir=runs`

After baseline sweep completes, run the architecture comparison:
```bash
python scripts/train_sweep.py --sweep configs/sweep_all_16x.yaml
```
</next_action>
