{
  "permissions": {
    "allow": [
      "WebSearch",
      "Bash(done)",
      "Bash(du:*)",
      "Bash(ls:*)",
      "Bash(python:*)",
      "Bash(\"D:/Projects/CNNAutoencoderProject/venv/Scripts/pip\" install tensorboard -q)",
      "Bash(\"venv/Scripts/python\" -c:*)",
      "Bash(\"D:/Projects/CNNAutoencoderProject/venv/Scripts/pip\" install scikit-image -q)",
      "Bash(\"D:/Projects/CNNAutoencoderProject/venv/Scripts/pip\" install opencv-python-headless -q)",
      "Bash(\"venv/Scripts/python\" -c \"\nimport torch, sys, os, numpy as np, random\n\n# Bypass src.__init__ by importing submodules directly\nsys.modules[''src''] = type\\(sys\\)\\(''src''\\)\nsys.modules[''src''].__path__ = [os.path.join\\(os.getcwd\\(\\), ''src''\\)]\n\nfrom src.models.resnet_autoencoder import ResNetAutoencoder\nfrom src.models.autoencoder import SARAutoencoder\nfrom src.losses.combined import CombinedLoss\nfrom src.data.datamodule import SARDataModule\n\nloss_fn = CombinedLoss\\(mse_weight=0.5, ssim_weight=0.5\\)\n\ndm = SARDataModule\\(''data/patches/metadata.npy'', batch_size=64, val_fraction=0.1\\)\nrandom.seed\\(42\\)\nval_indices = random.sample\\(range\\(len\\(dm.val_dataset\\)\\), min\\(2000, len\\(dm.val_dataset\\)\\)\\)\ndm.val_dataset = torch.utils.data.Subset\\(dm.val_dataset, val_indices\\)\nval_loader = dm.val_dataloader\\(\\)\n\ncheckpoints = [\n    \\(''baseline_c16_fast'', ''Baseline'', ''baseline''\\),\n    \\(''resnet_lite_v2_c16_20260126_210910'', ''ResNet-Lite v2 \\(old\\)'', ''resnet''\\),\n    \\(''resnet_c16_b32_sub10__20260127_000722'', ''Overnight \\(000722\\)'', ''resnet''\\),\n    \\(''resnet_c16_b32_sub10__20260127_022329'', ''Overnight \\(022329\\)'', ''resnet''\\),\n    \\(''residual_v1_c16'', ''Residual v1'', ''resnet''\\),\n]\n\nprint\\(f''Evaluating on {len\\(dm.val_dataset\\)} val patches...''\\)\nprint\\(\\)\n\nfor cp_name, label, mtype in checkpoints:\n    cp_path = f''notebooks/checkpoints/{cp_name}/best.pth''\n    if not os.path.exists\\(cp_path\\):\n        print\\(f''{label:<35} checkpoint not found''\\)\n        continue\n\n    cp = torch.load\\(cp_path, weights_only=False, map_location=''cuda''\\)\n    cfg = cp.get\\(''config'', {}\\)\n    bc = cfg.get\\(''base_channels'', 32\\)\n    lc = cfg.get\\(''latent_channels'', 16\\)\n    lr = cfg.get\\(''learning_rate'', ''?''\\)\n    ep = cp.get\\(''epoch'', ''?''\\)\n    bs = cfg.get\\(''batch_size'', ''?''\\)\n\n    if mtype == ''baseline'':\n        model = SARAutoencoder\\(latent_channels=lc\\)\n    else:\n        model = ResNetAutoencoder\\(latent_channels=lc, base_channels=bc\\)\n\n    model.load_state_dict\\(cp[''model_state_dict'']\\)\n    model.eval\\(\\).cuda\\(\\)\n\n    losses, psnrs, ssims = [], [], []\n    with torch.no_grad\\(\\):\n        for batch in val_loader:\n            batch = batch.cuda\\(\\)\n            out, _ = model\\(batch\\)\n            loss, metrics = loss_fn\\(out, batch\\)\n            losses.append\\(loss.item\\(\\)\\)\n            psnrs.append\\(metrics[''psnr'']\\)\n            ssims.append\\(metrics[''ssim'']\\)\n\n    info = f''ep={ep} lr={lr} bs={bs} bc={bc}''\n    print\\(f''{label:<35} loss={np.mean\\(losses\\):.4f}  PSNR={np.mean\\(psnrs\\):.2f}  SSIM={np.mean\\(ssims\\):.4f}  {info}''\\)\n    del model\n    torch.cuda.empty_cache\\(\\)\n\")"
    ]
  }
}
