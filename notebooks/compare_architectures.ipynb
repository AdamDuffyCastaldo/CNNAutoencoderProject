{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Architecture Comparison (Phase 4)\n",
    "\n",
    "Compare all trained architecture variants at 16x compression:\n",
    "- **Baseline**: Plain 4-layer encoder-decoder (2.3M params)\n",
    "- **ResNet-Lite v2**: Post-activation residual blocks (5.6M params) - **Best Available**\n",
    "- **Residual v1**: Pre-activation residual (23.8M params) - Training suboptimal\n",
    "- **Attention v1**: Pre-activation + CBAM (24M params) - Quick test only\n",
    "\n",
    "**Status:** Phase 4 wrapped up with ResNet-Lite v2 as best model. Residual/Attention training deferred.\n",
    "\n",
    "**Recommendation:** Proceed to Phase 5 with ResNet-Lite v2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "project_root = Path.cwd().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Project imports\n",
    "from src.data.datamodule import SARDataModule\n",
    "from src.models import SARAutoencoder, ResNetAutoencoder\n",
    "from src.models import ResidualAutoencoder, AttentionAutoencoder\n",
    "from src.losses.combined import CombinedLoss\n",
    "from src.evaluation.metrics import enl_ratio, edge_preservation_index, SARMetrics\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Define Model Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configurations\n",
    "# Each entry: (checkpoint_path, model_class, model_kwargs, status)\n",
    "MODEL_CONFIGS = OrderedDict([\n",
    "    ('Baseline', {\n",
    "        'checkpoint': 'checkpoints/baseline_c16_fast/best.pth',\n",
    "        'class': SARAutoencoder,\n",
    "        'kwargs': {'latent_channels': 16},\n",
    "        'status': 'complete',\n",
    "        'notes': 'Plain 4-layer encoder-decoder'\n",
    "    }),\n",
    "    ('ResNet-Lite v2', {\n",
    "        'checkpoint': 'checkpoints/resnet_lite_v2_c16/best.pth',\n",
    "        'class': ResNetAutoencoder,\n",
    "        'kwargs': {'latent_channels': 16, 'base_channels': 32},\n",
    "        'status': 'complete',\n",
    "        'notes': 'Post-activation residual blocks - BEST AVAILABLE'\n",
    "    }),\n",
    "    ('Residual v1', {\n",
    "        'checkpoint': 'checkpoints/residual_v1_c16/best.pth',\n",
    "        'class': ResidualAutoencoder,\n",
    "        'kwargs': {'latent_channels': 16, 'base_channels': 64},\n",
    "        'status': 'suboptimal',\n",
    "        'notes': 'LR too conservative (1e-5), underperformed baseline'\n",
    "    }),\n",
    "    ('Attention v1', {\n",
    "        'checkpoint': 'checkpoints/attention_v1_c16/quick_test.pth',\n",
    "        'class': AttentionAutoencoder,\n",
    "        'kwargs': {'latent_channels': 16, 'base_channels': 64},\n",
    "        'status': 'incomplete',\n",
    "        'notes': 'Quick test only (50 batches), not representative'\n",
    "    }),\n",
    "])\n",
    "\n",
    "print(f\"Configured {len(MODEL_CONFIGS)} models for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "model_info = {}\n",
    "\n",
    "for name, config in MODEL_CONFIGS.items():\n",
    "    checkpoint_path = Path(config['checkpoint'])\n",
    "    \n",
    "    if not checkpoint_path.exists():\n",
    "        print(f\"[SKIP] {name}: checkpoint not found at {checkpoint_path}\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load checkpoint\n",
    "        checkpoint = torch.load(checkpoint_path, weights_only=False, map_location=device)\n",
    "        \n",
    "        # Create model\n",
    "        model = config['class'](**config['kwargs'])\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # Store model and info\n",
    "        models[name] = model\n",
    "        model_info[name] = {\n",
    "            'params': model.count_parameters()['total'],\n",
    "            'status': config['status'],\n",
    "            'notes': config['notes'],\n",
    "            'epoch': checkpoint.get('epoch', 'unknown'),\n",
    "            'best_val_loss': checkpoint.get('best_val_loss', None),\n",
    "        }\n",
    "        \n",
    "        print(f\"[OK] {name}: {model_info[name]['params']:,} params, status={config['status']}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] {name}: {e}\")\n",
    "\n",
    "print(f\"\\nLoaded {len(models)} models successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 4. Load Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "DATA_PATH = \"D:/Projects/CNNAutoencoderProject/data/patches/metadata.npy\"\n",
    "BATCH_SIZE = 32\n",
    "VAL_FRACTION = 0.1\n",
    "\n",
    "print(\"Loading validation data...\")\n",
    "dm = SARDataModule(\n",
    "    patches_path=DATA_PATH,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=4,\n",
    "    val_fraction=VAL_FRACTION,\n",
    ")\n",
    "\n",
    "# Use a consistent subset for fair comparison\n",
    "import random\n",
    "random.seed(42)  # Reproducible subset\n",
    "VAL_SUBSET = 0.05  # 5% of validation for quick comparison\n",
    "\n",
    "full_val_size = len(dm.val_dataset)\n",
    "val_subset_size = int(full_val_size * VAL_SUBSET)\n",
    "val_indices = random.sample(range(full_val_size), val_subset_size)\n",
    "dm.val_dataset = torch.utils.data.Subset(dm.val_dataset, val_indices)\n",
    "\n",
    "val_loader = dm.val_dataloader()\n",
    "\n",
    "print(f\"Validation patches: {len(dm.val_dataset):,} (5% subset)\")\n",
    "print(f\"Validation batches: {len(val_loader):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 5. Evaluate All Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CombinedLoss(mse_weight=0.5, ssim_weight=0.5)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    \n",
    "    losses, psnrs, ssims = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = batch.to(device)\n",
    "            output, _ = model(batch)\n",
    "            loss, metrics = loss_fn(output, batch)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "            psnrs.append(metrics['psnr'])\n",
    "            ssims.append(metrics['ssim'])\n",
    "    \n",
    "    results[name] = {\n",
    "        'val_loss': np.mean(losses),\n",
    "        'val_psnr': np.mean(psnrs),\n",
    "        'val_ssim': np.mean(ssims),\n",
    "        'params': model_info[name]['params'],\n",
    "        'status': model_info[name]['status'],\n",
    "        'notes': model_info[name]['notes'],\n",
    "    }\n",
    "    \n",
    "    print(f\"  Loss: {results[name]['val_loss']:.4f}\")\n",
    "    print(f\"  PSNR: {results[name]['val_psnr']:.2f} dB\")\n",
    "    print(f\"  SSIM: {results[name]['val_ssim']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 6. SAR-Specific Metrics (Sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample batch for SAR metrics\n",
    "sample_batch = next(iter(val_loader))[:4].to(device)\n",
    "\n",
    "for name, model in models.items():\n",
    "    if model_info[name]['status'] == 'incomplete':\n",
    "        print(f\"\\n{name}: [SKIPPED - incomplete training]\")\n",
    "        results[name]['enl_ratio'] = None\n",
    "        results[name]['epi'] = None\n",
    "        continue\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        output, _ = model(sample_batch)\n",
    "    \n",
    "    # Compute ENL ratio and EPI on first sample\n",
    "    orig = sample_batch[0, 0].cpu().numpy()\n",
    "    recon = output[0, 0].cpu().numpy()\n",
    "    \n",
    "    enl_result = enl_ratio(orig, recon)\n",
    "    epi_result = edge_preservation_index(orig, recon)\n",
    "    \n",
    "    results[name]['enl_ratio'] = enl_result['enl_ratio']\n",
    "    results[name]['epi'] = epi_result\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  ENL ratio: {enl_result['enl_ratio']:.3f} (target: 0.8-1.2)\")\n",
    "    print(f\"  EPI: {epi_result:.3f} (target: >0.85)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 7. Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get baseline for comparison\n",
    "baseline_psnr = results.get('Baseline', {}).get('val_psnr', 20.47)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"Architecture Comparison Summary (16x Compression)\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Model':<20} {'Params':>10} {'PSNR':>10} {'SSIM':>10} {'ENL':>10} {'EPI':>10} {'vs Base':>10} {'Status':<15}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for name, r in results.items():\n",
    "    params_str = f\"{r['params']/1e6:.1f}M\"\n",
    "    psnr_str = f\"{r['val_psnr']:.2f} dB\"\n",
    "    ssim_str = f\"{r['val_ssim']:.3f}\"\n",
    "    \n",
    "    enl_str = f\"{r['enl_ratio']:.3f}\" if r.get('enl_ratio') else \"N/A\"\n",
    "    epi_str = f\"{r['epi']:.3f}\" if r.get('epi') else \"N/A\"\n",
    "    \n",
    "    diff = r['val_psnr'] - baseline_psnr\n",
    "    diff_str = f\"{diff:+.2f} dB\" if name != 'Baseline' else \"-\"\n",
    "    \n",
    "    print(f\"{name:<20} {params_str:>10} {psnr_str:>10} {ssim_str:>10} {enl_str:>10} {epi_str:>10} {diff_str:>10} {r['status']:<15}\")\n",
    "\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Find best model\n",
    "complete_models = {k: v for k, v in results.items() if v['status'] == 'complete'}\n",
    "if complete_models:\n",
    "    best_name = max(complete_models.keys(), key=lambda k: complete_models[k]['val_psnr'])\n",
    "    print(f\"\\nBest available model: {best_name} ({results[best_name]['val_psnr']:.2f} dB)\")\n",
    "    print(f\"Recommendation: Use {best_name} for Phase 5 (Full Image Inference)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 8. Visual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual comparison on sample patches\n",
    "n_samples = 3\n",
    "complete_models_list = [name for name in models.keys() if model_info[name]['status'] == 'complete']\n",
    "\n",
    "fig, axes = plt.subplots(n_samples, len(complete_models_list) + 2, figsize=(4 * (len(complete_models_list) + 2), 4 * n_samples))\n",
    "\n",
    "sample_batch = next(iter(val_loader))[:n_samples].to(device)\n",
    "\n",
    "for i in range(n_samples):\n",
    "    orig = sample_batch[i, 0].cpu().numpy()\n",
    "    \n",
    "    # Original\n",
    "    axes[i, 0].imshow(orig, cmap='gray')\n",
    "    axes[i, 0].set_title('Original' if i == 0 else '')\n",
    "    axes[i, 0].axis('off')\n",
    "    \n",
    "    # Each complete model\n",
    "    for j, name in enumerate(complete_models_list):\n",
    "        model = models[name]\n",
    "        with torch.no_grad():\n",
    "            output, _ = model(sample_batch[i:i+1])\n",
    "        recon = output[0, 0].cpu().numpy()\n",
    "        \n",
    "        axes[i, j + 1].imshow(recon, cmap='gray')\n",
    "        if i == 0:\n",
    "            axes[i, j + 1].set_title(f\"{name}\\n{results[name]['val_psnr']:.2f} dB\")\n",
    "        axes[i, j + 1].axis('off')\n",
    "    \n",
    "    # Difference (best model)\n",
    "    best_model = models[complete_models_list[-1]]  # Last complete model (usually best)\n",
    "    with torch.no_grad():\n",
    "        output, _ = best_model(sample_batch[i:i+1])\n",
    "    recon = output[0, 0].cpu().numpy()\n",
    "    diff = np.abs(orig - recon)\n",
    "    \n",
    "    axes[i, -1].imshow(diff, cmap='hot', vmin=0, vmax=0.3)\n",
    "    axes[i, -1].set_title('Diff (Best)' if i == 0 else '')\n",
    "    axes[i, -1].axis('off')\n",
    "\n",
    "plt.suptitle('Architecture Comparison - Sample Reconstructions', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('compare_architectures_visual.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nSaved: compare_architectures_visual.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "## 9. Phase 4 Success Criteria Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"Phase 4 Success Criteria Assessment\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "criteria = [\n",
    "    (\"ResidualBlock forward pass preserves dimensions\", True, \"Implemented and tested\"),\n",
    "    (\"CBAM applies attention without errors\", True, \"Implemented and tested\"),\n",
    "    (\"Residual (Variant B) >= +1.5 dB over baseline (22.0 dB)\", False, \"Deferred - training suboptimal\"),\n",
    "    (\"Attention (Variant C) >= +0.5 dB over Residual\", False, \"Deferred - quick test only\"),\n",
    "    (\"ENL ratio 0.8-1.2 for all variants\", True, \"Met for complete models\"),\n",
    "]\n",
    "\n",
    "passed = 0\n",
    "for criterion, status, note in criteria:\n",
    "    icon = \"PASS\" if status else \"DEFER\"\n",
    "    passed += 1 if status else 0\n",
    "    print(f\"[{icon}] {criterion}\")\n",
    "    print(f\"       {note}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Result: {passed}/{len(criteria)} criteria met\")\n",
    "print(\"Status: PARTIAL COMPLETION - Training improvements deferred\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nRecommendation:\")\n",
    "print(\"- Proceed to Phase 5 with ResNet-Lite v2 (21.20 dB, best available)\")\n",
    "print(\"- Return to Phase 4 later to complete Residual/Attention training\")\n",
    "print(\"- Training infrastructure (warmup, AdamW) ready for future runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "## 10. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert results for JSON serialization\n",
    "json_results = {}\n",
    "for name, r in results.items():\n",
    "    json_results[name] = {\n",
    "        'params': int(r['params']),\n",
    "        'val_loss': float(r['val_loss']),\n",
    "        'val_psnr': float(r['val_psnr']),\n",
    "        'val_ssim': float(r['val_ssim']),\n",
    "        'enl_ratio': float(r['enl_ratio']) if r.get('enl_ratio') else None,\n",
    "        'epi': float(r['epi']) if r.get('epi') else None,\n",
    "        'status': r['status'],\n",
    "        'notes': r['notes'],\n",
    "    }\n",
    "\n",
    "output = {\n",
    "    'comparison_date': datetime.now().isoformat(),\n",
    "    'compression_ratio': 16,\n",
    "    'validation_samples': len(dm.val_dataset),\n",
    "    'best_model': 'ResNet-Lite v2',\n",
    "    'phase_status': 'partial_completion',\n",
    "    'results': json_results,\n",
    "}\n",
    "\n",
    "with open('compare_architectures_results.json', 'w') as f:\n",
    "    json.dump(output, f, indent=2)\n",
    "\n",
    "print(f\"Saved results to: compare_architectures_results.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "**Phase 4 Status:** Partial completion\n",
    "\n",
    "**Best Available Model:** ResNet-Lite v2\n",
    "- PSNR: ~21.2 dB (+0.73 dB over baseline)\n",
    "- SSIM: ~0.726\n",
    "- Parameters: 5.6M\n",
    "\n",
    "**Deferred Work:**\n",
    "- Residual (Variant B) full training\n",
    "- Attention (Variant C) full training\n",
    "\n",
    "**Next Step:** Phase 5 - Full Image Inference with ResNet-Lite v2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
